/home/Minwoo/.conda/envs/DecomposeTransformer/bin/python /home/Minwoo/LESN/Decompose/DecomposeTransformer/Getting_Started/head_prune.py
Loading the model.
{'model_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'YahooAnswersTopics', 'num_labels': 10, 'cache_dir': 'Models'}
The model fabriceyhc/bert-base-uncased-yahoo_answers_topics is loaded.
{'dataset_name': 'YahooAnswersTopics', 'path': 'yahoo_answers_topics', 'config_name': 'yahoo_answers_topics', 'text_column': 'question_title', 'label_column': 'topic', 'cache_dir': 'Datasets/Yahoo', 'task_type': 'classification'}
Loading cached dataset YahooAnswersTopics.
The dataset YahooAnswersTopics is loaded
Iteration:   0%|          | 0/4375 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Iteration: 100%|██████████| 4375/4375 [2:02:50<00:00,  1.68s/it]
Class 0 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 0 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (0, 1), (5, 3), (6, 3)]
Class 0 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 9), (9, 2), (2, 4), (3, 9), (9, 0), (11, 1), (3, 4), (5, 11), (8, 6), (7, 6), (6, 1)]
Class 0 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (3, 3), (11, 7), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 0 60 prunning
total prune number : 60
prune head list
[(8, 7), (10, 8), (4, 11), (3, 10), (11, 10), (5, 2), (0, 8), (9, 3), (6, 7), (11, 4), (10, 9), (2, 3)]
Class 0 72 prunning
total prune number : 72
prune head list
[(6, 10), (3, 6), (4, 5), (1, 0), (6, 5), (2, 2), (11, 2), (5, 8), (1, 1), (4, 10), (0, 7), (4, 6)]
Class 0 84 prunning
total prune number : 84
prune head list
[(7, 1), (10, 3), (10, 2), (1, 6), (10, 11), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 0 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (8, 11), (2, 7)]
Evaluating: 100%|██████████| 1875/1875 [12:37<00:00,  2.48it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 1 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 1 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (0, 11), (11, 8), (6, 2), (5, 3), (0, 1), (6, 3)]
Class 1 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (3, 9), (9, 0), (2, 4), (11, 1), (5, 11), (3, 4), (8, 6), (7, 6), (6, 1)]
Class 1 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (11, 7), (3, 3), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 1 60 prunning
total prune number : 60
prune head list
[(8, 7), (4, 11), (10, 8), (3, 10), (11, 10), (9, 3), (0, 8), (5, 2), (6, 7), (10, 9), (11, 4), (2, 3)]
Class 1 72 prunning
total prune number : 72
prune head list
[(6, 10), (4, 5), (3, 6), (1, 0), (6, 5), (5, 8), (2, 2), (4, 10), (11, 2), (1, 1), (0, 7), (7, 1)]
Class 1 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 3), (1, 6), (10, 11), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 1 96 prunning
total prune number : 96
prune head list
[(2, 1), (7, 11), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:35<00:00,  2.48it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 2 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 2 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (0, 1), (6, 3)]
Class 2 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 9), (9, 2), (2, 4), (9, 0), (3, 9), (11, 1), (5, 11), (3, 4), (7, 6), (8, 6), (6, 1)]
Class 2 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (11, 7), (3, 3), (3, 11), (9, 7), (11, 3), (2, 8), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 2 60 prunning
total prune number : 60
prune head list
[(10, 8), (8, 7), (4, 11), (3, 10), (11, 10), (0, 8), (10, 9), (9, 3), (5, 2), (6, 7), (11, 4), (2, 3)]
Class 2 72 prunning
total prune number : 72
prune head list
[(4, 5), (3, 6), (6, 10), (1, 0), (11, 2), (2, 2), (5, 8), (6, 5), (4, 10), (1, 1), (0, 7), (4, 6)]
Class 2 84 prunning
total prune number : 84
prune head list
[(7, 1), (10, 2), (10, 3), (10, 11), (1, 6), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 2 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (5, 10), (8, 10), (9, 8), (6, 4), (1, 8), (9, 1), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:49<00:00,  2.44it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 3 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 3 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (0, 11), (11, 8), (6, 2), (5, 3), (0, 1), (6, 3)]
Class 3 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (3, 9), (2, 4), (9, 0), (11, 1), (5, 11), (3, 4), (8, 6), (7, 6), (6, 1)]
Class 3 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (3, 3), (11, 7), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 3 60 prunning
total prune number : 60
prune head list
[(8, 7), (10, 8), (4, 11), (3, 10), (11, 10), (0, 8), (9, 3), (6, 7), (5, 2), (11, 4), (2, 3), (10, 9)]
Class 3 72 prunning
total prune number : 72
prune head list
[(6, 10), (4, 5), (3, 6), (6, 5), (1, 0), (2, 2), (11, 2), (5, 8), (4, 10), (1, 1), (0, 7), (7, 1)]
Class 3 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 3), (1, 6), (10, 11), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 3 96 prunning
total prune number : 96
prune head list
[(2, 1), (7, 11), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:53<00:00,  2.42it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 4 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 4 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 5), (8, 4), (0, 10), (0, 3), (0, 11), (11, 8), (6, 2), (5, 3), (6, 3), (0, 1)]
Class 4 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (2, 4), (3, 9), (9, 0), (11, 1), (5, 11), (3, 4), (7, 6), (8, 6), (6, 1)]
Class 4 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (3, 3), (9, 7), (11, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 4 60 prunning
total prune number : 60
prune head list
[(4, 11), (8, 7), (3, 10), (10, 8), (11, 10), (0, 8), (9, 3), (5, 2), (11, 4), (6, 7), (2, 3), (10, 9)]
Class 4 72 prunning
total prune number : 72
prune head list
[(4, 5), (3, 6), (6, 10), (1, 0), (6, 5), (11, 2), (2, 2), (5, 8), (4, 10), (1, 1), (7, 1), (0, 7)]
Class 4 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 3), (10, 11), (1, 6), (2, 0), (2, 9), (10, 0), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 4 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 7), (2, 11), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:42<00:00,  2.46it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 5 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 5 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (0, 1), (6, 3)]
Class 5 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (3, 9), (2, 4), (9, 0), (11, 1), (5, 11), (3, 4), (8, 6), (7, 6), (6, 1)]
Class 5 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (11, 7), (3, 3), (9, 7), (3, 11), (11, 3), (2, 8), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 5 60 prunning
total prune number : 60
prune head list
[(8, 7), (4, 11), (10, 8), (3, 10), (11, 10), (11, 4), (9, 3), (6, 7), (0, 8), (10, 9), (5, 2), (2, 3)]
Class 5 72 prunning
total prune number : 72
prune head list
[(4, 5), (6, 10), (3, 6), (11, 2), (1, 0), (6, 5), (5, 8), (4, 10), (2, 2), (1, 1), (0, 7), (7, 1)]
Class 5 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 11), (10, 3), (1, 6), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 5 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (1, 8), (9, 1), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [13:04<00:00,  2.39it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 6 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 6 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 5), (8, 4), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (6, 3), (0, 1)]
Class 6 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 9), (9, 2), (2, 4), (3, 9), (11, 1), (9, 0), (3, 4), (5, 11), (8, 6), (7, 6), (6, 1)]
Class 6 48 prunning
total prune number : 48
prune head list
[(11, 5), (0, 5), (11, 7), (3, 3), (9, 7), (3, 11), (11, 3), (2, 8), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 6 60 prunning
total prune number : 60
prune head list
[(8, 7), (4, 11), (10, 8), (3, 10), (11, 10), (0, 8), (9, 3), (5, 2), (11, 4), (6, 7), (10, 9), (2, 3)]
Class 6 72 prunning
total prune number : 72
prune head list
[(3, 6), (6, 10), (4, 5), (11, 2), (1, 0), (6, 5), (2, 2), (5, 8), (1, 1), (4, 10), (0, 7), (7, 1)]
Class 6 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 11), (10, 3), (1, 6), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 6 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (1, 8), (9, 1), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [13:03<00:00,  2.39it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 7 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 7 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (6, 3), (0, 1)]
Class 7 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (3, 9), (2, 4), (9, 0), (11, 1), (5, 11), (3, 4), (6, 1), (8, 6), (7, 6)]
Class 7 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 7), (11, 5), (3, 3), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 7 60 prunning
total prune number : 60
prune head list
[(8, 7), (4, 11), (3, 10), (10, 8), (11, 10), (0, 8), (6, 7), (5, 2), (9, 3), (11, 4), (2, 3), (10, 9)]
Class 7 72 prunning
total prune number : 72
prune head list
[(6, 10), (4, 5), (3, 6), (6, 5), (1, 0), (5, 8), (2, 2), (4, 10), (1, 1), (11, 2), (0, 7), (4, 6)]
Class 7 84 prunning
total prune number : 84
prune head list
[(7, 1), (10, 2), (10, 11), (10, 3), (1, 6), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 7 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:52<00:00,  2.43it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 8 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 8 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 5), (8, 4), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (0, 1), (6, 3)]
Class 8 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (3, 9), (2, 4), (9, 0), (11, 1), (3, 4), (5, 11), (7, 6), (8, 6), (6, 1)]
Class 8 48 prunning
total prune number : 48
prune head list
[(11, 7), (0, 5), (11, 5), (3, 3), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 8 60 prunning
total prune number : 60
prune head list
[(8, 7), (4, 11), (3, 10), (10, 8), (11, 10), (9, 3), (11, 4), (0, 8), (5, 2), (2, 3), (10, 9), (6, 7)]
Class 8 72 prunning
total prune number : 72
prune head list
[(6, 10), (3, 6), (4, 5), (1, 0), (6, 5), (2, 2), (5, 8), (11, 2), (1, 1), (4, 10), (0, 7), (4, 6)]
Class 8 84 prunning
total prune number : 84
prune head list
[(7, 1), (10, 2), (10, 3), (10, 11), (1, 6), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 8 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:34<00:00,  2.49it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Class 9 12 prunning
total prune number : 12
prune head list
[(10, 5), (9, 4), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Class 9 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 5), (8, 4), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (0, 1), (6, 3)]
Class 9 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 9), (9, 2), (2, 4), (3, 9), (9, 0), (11, 1), (5, 11), (3, 4), (7, 6), (8, 6), (6, 1)]
Class 9 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (3, 3), (11, 7), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Class 9 60 prunning
total prune number : 60
prune head list
[(4, 11), (8, 7), (10, 8), (3, 10), (11, 10), (9, 3), (0, 8), (10, 9), (6, 7), (11, 4), (5, 2), (2, 3)]
Class 9 72 prunning
total prune number : 72
prune head list
[(4, 5), (3, 6), (6, 10), (1, 0), (11, 2), (6, 5), (5, 8), (2, 2), (1, 1), (4, 10), (0, 7), (7, 1)]
Class 9 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 3), (10, 11), (1, 6), (2, 0), (2, 9), (10, 0), (7, 9), (3, 5), (1, 4), (7, 4)]
Class 9 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [13:08<00:00,  2.38it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000

Total 12 prunning
total prune number : 12
prune head list
[(9, 4), (10, 5), (8, 0), (7, 3), (9, 10), (1, 2), (1, 3), (5, 6), (5, 1), (8, 3), (0, 2), (7, 7)]
Total 24 prunning
total prune number : 24
prune head list
[(5, 7), (10, 1), (8, 4), (8, 5), (0, 10), (0, 3), (11, 8), (0, 11), (6, 2), (5, 3), (0, 1), (6, 3)]
Total 36 prunning
total prune number : 36
prune head list
[(5, 0), (9, 2), (9, 9), (3, 9), (2, 4), (9, 0), (11, 1), (5, 11), (3, 4), (8, 6), (7, 6), (6, 1)]
Total 48 prunning
total prune number : 48
prune head list
[(0, 5), (11, 5), (11, 7), (3, 3), (9, 7), (3, 11), (2, 8), (11, 3), (3, 2), (1, 5), (4, 8), (4, 1)]
Total 60 prunning
total prune number : 60
prune head list
[(8, 7), (4, 11), (10, 8), (3, 10), (11, 10), (0, 8), (9, 3), (5, 2), (6, 7), (11, 4), (10, 9), (2, 3)]
Total 72 prunning
total prune number : 72
prune head list
[(6, 10), (4, 5), (3, 6), (1, 0), (6, 5), (11, 2), (2, 2), (5, 8), (4, 10), (1, 1), (0, 7), (7, 1)]
Total 84 prunning
total prune number : 84
prune head list
[(4, 6), (10, 2), (10, 3), (10, 11), (1, 6), (2, 0), (10, 0), (2, 9), (7, 9), (3, 5), (1, 4), (7, 4)]
Total 96 prunning
total prune number : 96
prune head list
[(7, 11), (2, 1), (6, 11), (8, 10), (5, 10), (9, 8), (6, 4), (9, 1), (1, 8), (2, 11), (2, 7), (8, 11)]
Evaluating: 100%|██████████| 1875/1875 [12:56<00:00,  2.42it/s]
Loss: 1.2278
Precision: 0.6369, Recall: 0.6141, F1-Score: 0.6174
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      6000
           1       0.70      0.60      0.65      6000
           2       0.71      0.61      0.66      6000
           3       0.47      0.45      0.46      6000
           4       0.75      0.73      0.74      6000
           5       0.91      0.67      0.77      6000
           6       0.51      0.42      0.46      6000
           7       0.43      0.74      0.54      6000
           8       0.61      0.72      0.66      6000
           9       0.73      0.68      0.70      6000

    accuracy                           0.61     60000
   macro avg       0.64      0.61      0.62     60000
weighted avg       0.64      0.61      0.62     60000


Process finished with exit code 0
