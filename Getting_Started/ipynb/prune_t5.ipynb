{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574f39c9-c15e-4352-8bfd-e1acdc0ffb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from utils.model_utils.load_model import load_model\n",
    "from utils.helper import ModelConfig\n",
    "from utils.dataset_utils.load_dataset import load_data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cc17d8-3184-441c-89c8-a662ca7237e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Salesforce/codet5-base-multi-sum\"\n",
    "task_type = \"seq2seq\"\n",
    "architectures = \"T5\"\n",
    "dataset_name = \"Go\"\n",
    "num_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5268e5-e6bd-4ae5-9f0d-cf0084077d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e56880-d19b-405d-9806-9a45d1255fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = None\n",
    "model_config = ModelConfig(\n",
    "    model_name=model_name,\n",
    "    task_type=task_type,\n",
    "    dataset_name=dataset_name,\n",
    "    checkpoint=checkpoint,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127f9b5f-e5fc-40eb-89dc-c17539242553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/Minwoo/LESN/Decompose/DecomposeTransformer/Models/Configs/seq2seq/Salesforce/codet5-base-multi-sum exists.\n",
      "Loading the model.\n",
      "The model Salesforce/codet5-base-multi-sum is loaded.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, checkpoint = load_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3fc3394-407e-47a6-b03e-9c77e6e6dfe4",
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab3ab86-0f62-4fe7-93fb-55d2a6ff6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset Go\n",
      "Load cached dataset.\n",
      "The dataset Go is loaded\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "        model_config, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e182738-1e87-45ae-b9c2-406f2079f306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func (s *CreateKeysAndCertificateInput) SetSetAsActive(v bool) *CreateKeysAndCertificateInput {\n",
      "\ts.SetAsActive = &v\n",
      "\treturn s\n",
      "}\n",
      "// SetSetAsActive sets the SetAsActive field's value.\n",
      "SetSetAsActive sets the SetAsActive field s value.\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_dataloader):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    print(tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "    print(tokenizer.decode(labels[0], skip_special_tokens=True))\n",
    "    outputs = model.generate(input_ids[0].unsqueeze(0))\n",
    "    \n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(decoded_output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6840090-be70-4d31-9aa6-e65bef2635fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da6d9e9-922b-4e2c-90d3-abddcc1d0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "class WeightRemover:\n",
    "    def __init__(self, model, device=\"cuda:0\", p=0.8):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.p = p\n",
    "        self.results = {\"layer\": [], \"input\": [], \"output\": []}\n",
    "\n",
    "    def hook(self, layer, input, output):\n",
    "        self.results[\"layer\"].append(layer)\n",
    "        self.results[\"input\"].append(input[0].to('cpu'))\n",
    "        self.results[\"output\"].append(output[0].to('cpu'))\n",
    "\n",
    "    def register_hooks(self):\n",
    "        handle_list = []\n",
    "        for layer in self.model.modules():\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                handle = layer.register_forward_hook(self.hook)\n",
    "                handle_list.append(handle)\n",
    "        return handle_list\n",
    "\n",
    "    def remove_hooks(self, handle_list):\n",
    "        for handle in handle_list:\n",
    "            handle.remove()\n",
    "\n",
    "    def remove_weights(self, layer):\n",
    "        current_weight = layer.weight.clone()\n",
    "        if layer.bias is not None:\n",
    "            current_bias = layer.bias.clone()\n",
    "        else:\n",
    "            current_bias = None\n",
    "\n",
    "        mean = torch.mean(current_weight, dim=1, keepdim=True)\n",
    "        std = torch.std(current_weight, dim=1, keepdim=True)\n",
    "        z_scores = (current_weight - mean) / std\n",
    "\n",
    "        lower_z, upper_z = norm.ppf(0.45), norm.ppf(0.55)\n",
    "        mask = torch.logical_and(z_scores >= lower_z, z_scores < upper_z)\n",
    "\n",
    "        current_weight[mask] = 0\n",
    "        all_zeros = ~mask.any(dim=1)\n",
    "        if current_bias is not None:\n",
    "            current_bias[all_zeros] = 0\n",
    "        self.set_parameters(layer, current_weight, current_bias)\n",
    "\n",
    "    def set_parameters(self, layer, weight, bias):\n",
    "        layer.weight.data = weight\n",
    "        if bias is not None:\n",
    "            layer.bias.data = bias\n",
    "\n",
    "    def process(self, input_tensor, decoder_input_ids):\n",
    "        self.results = {\"layer\": [], \"input\": [], \"output\": []}\n",
    "        handle_list = self.register_hooks()\n",
    "        output = self.model(input_ids=input_tensor.to(self.device), decoder_input_ids=decoder_input_ids.to(self.device))\n",
    "        self.remove_hooks(handle_list)\n",
    "        return output\n",
    "        \n",
    "    def apply_removal(self):\n",
    "        total_original_weights = 0\n",
    "        total_remaining_weights = 0\n",
    "\n",
    "        for idx, layer in enumerate(self.results[\"layer\"]):\n",
    "            current_weight = layer.weight\n",
    "            original_non_zero_weights = torch.sum(current_weight != 0).item()\n",
    "            total_original_weights += original_non_zero_weights\n",
    "\n",
    "            if torch.sum(current_weight != 0) > torch.numel(current_weight) * self.p:\n",
    "                self.results[\"output\"][idx] = self.results[\"output\"][idx].to(self.device)\n",
    "                self.remove_weights(layer)\n",
    "                self.results[\"output\"][idx] = self.results[\"output\"][idx].to('cpu')\n",
    "\n",
    "            remaining_non_zero_weights = torch.sum(layer.weight != 0).item()\n",
    "            total_remaining_weights += remaining_non_zero_weights\n",
    "\n",
    "            print(f\"Layer {idx} - Original non-zero weights: {original_non_zero_weights}, Remaining non-zero weights: {remaining_non_zero_weights}, Reduction: {original_non_zero_weights - remaining_non_zero_weights}\")\n",
    "\n",
    "        print(f\"Total original non-zero weights: {total_original_weights}\")\n",
    "        print(f\"Total remaining non-zero weights: {total_remaining_weights}\")\n",
    "        print(f\"Total reduction: {total_original_weights - total_remaining_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0b8dc-8aa8-42b0-9f15-ed193652213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcernIdentification:\n",
    "    def __init__(self, ref_model, model, device='cuda:0', p=0.7):\n",
    "        self.ref_model = ref_model.to(device)\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.p = p\n",
    "        self.original_results = {\"layer\": [], \"input\": [], \"output\": []}\n",
    "        self.current_results = {\"layer\": [], \"input\": [], \"output\": []}\n",
    "\n",
    "    def original_hook(self, layer, input, output):\n",
    "        self.original_results[\"layer\"].append(layer)\n",
    "        self.original_results[\"input\"].append(input[0].to('cpu'))\n",
    "        self.original_results[\"output\"].append(output[0].to('cpu'))\n",
    "\n",
    "    def current_hook(self, layer, input, output):\n",
    "        self.current_results[\"layer\"].append(layer)\n",
    "        self.current_results[\"input\"].append(input[0].to('cpu'))\n",
    "        self.current_results[\"output\"].append(output[0].to('cpu'))\n",
    "\n",
    "    def register_hooks(self, model, hook):\n",
    "        handle_list = []\n",
    "        for layer in model.modules():\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                handle = layer.register_forward_hook(hook)\n",
    "                handle_list.append(handle)\n",
    "        return handle_list\n",
    "\n",
    "    def remove_hooks(self, handle_list):\n",
    "        for handle in handle_list:\n",
    "            handle.remove()\n",
    "\n",
    "    def prune(self, ref_model, model, original_output, output):\n",
    "        current_weight = model.weight.clone()\n",
    "        if model.bias is not None:\n",
    "            current_bias = model.bias.clone()\n",
    "        else:\n",
    "            current_bias = None\n",
    "        original_weight = ref_model.weight.clone()\n",
    "        \n",
    "        if ref_model.bias is not None:\n",
    "            original_bias = ref_model.bias.clone()\n",
    "        else:\n",
    "            original_bias = None\n",
    "        shape = current_weight.shape\n",
    "\n",
    "        output_loss = output - original_output\n",
    "        if len(output_loss.shape) > len(shape):\n",
    "            output_loss = output_loss[:, 0, :]\n",
    "            \n",
    "        positive_loss_mask = (\n",
    "            torch.all(output_loss > 0, dim=0).unsqueeze(1).expand(-1, shape[1])\n",
    "        )\n",
    "\n",
    "        original_weight_std = safe_std(original_weight, dim=1, keepdim=True)\n",
    "        current_weight_std = safe_std(\n",
    "            current_weight,\n",
    "            epsilon=original_weight_std,\n",
    "            unbiased=True,\n",
    "            dim=1,\n",
    "            keepdim=True,\n",
    "        )\n",
    "\n",
    "        padded_positive = torch.where(\n",
    "            current_weight > 0, current_weight, torch.tensor(float(\"nan\"))\n",
    "        )\n",
    "        padded_negative = torch.where(\n",
    "            current_weight < 0, current_weight, torch.tensor(float(\"nan\"))\n",
    "        )\n",
    "        positive_mean = torch.nanmean(padded_positive, dim=1, keepdim=True)\n",
    "        negative_mean = torch.nanmean(padded_negative, dim=1, keepdim=True)\n",
    "\n",
    "        positive_std = safe_std(\n",
    "            current_weight,\n",
    "            epsilon=current_weight_std,\n",
    "            unbiased=True,\n",
    "            dim=1,\n",
    "            keepdim=True,\n",
    "        )\n",
    "        negative_std = safe_std(\n",
    "            current_weight,\n",
    "            epsilon=current_weight_std,\n",
    "            unbiased=True,\n",
    "            dim=1,\n",
    "            keepdim=True,\n",
    "        )\n",
    "\n",
    "        positive_scores = (padded_positive - positive_mean) / positive_std\n",
    "        negative_scores = (padded_negative - negative_mean) / negative_std\n",
    "\n",
    "        positive_median = torch.nanmedian(padded_positive, dim=1, keepdim=True)\n",
    "        negative_median = torch.nanmedian(padded_negative, dim=1, keepdim=True)\n",
    "        lower_z, upper_z = norm.ppf(0.1), norm.ppf(0.3)\n",
    "\n",
    "        positive_remove_mask = torch.where(\n",
    "            positive_mean < positive_median.values,\n",
    "            positive_scores <= lower_z,\n",
    "            torch.logical_and(positive_scores >= lower_z, positive_scores < upper_z),\n",
    "        )\n",
    "\n",
    "        negative_remove_mask = torch.where(\n",
    "            negative_mean < negative_median.values,\n",
    "            torch.logical_and(negative_scores < -lower_z, negative_scores >= -upper_z),\n",
    "            negative_scores >= -upper_z,\n",
    "        )\n",
    "\n",
    "        remove_mask = torch.where(\n",
    "            ~positive_loss_mask, positive_remove_mask, negative_remove_mask\n",
    "        )\n",
    "\n",
    "        current_weight[remove_mask] = 0\n",
    "\n",
    "        all_zeros = ~remove_mask.any(dim=1)\n",
    "        if current_bias is not None:\n",
    "            current_bias[all_zeros] = 0\n",
    "        self.set_parameters(model, current_weight, current_bias)\n",
    "\n",
    "    def set_parameters(self, layer, weight, bias):\n",
    "        layer.weight.data = weight\n",
    "        if bias is not None:\n",
    "            layer.bias.data = bias\n",
    "\n",
    "    def process(self, input_tensor, decoder_input_ids):\n",
    "        self.original_results = {\"layer\": [], \"input\": [], \"output\": []}\n",
    "        self.current_results = {\"layer\": [], \"input\": [], \"output\": []}\n",
    "\n",
    "        handle_list = self.register_hooks(self.model, self.current_hook)\n",
    "        self.model(input_ids=input_tensor.to(self.device), decoder_input_ids=decoder_input_ids.to(self.device))\n",
    "        self.remove_hooks(handle_list)\n",
    "        handle_list = self.register_hooks(self.ref_model, self.original_hook)\n",
    "        self.ref_model(input_ids=input_tensor.to(self.device), decoder_input_ids=decoder_input_ids.to(self.device))\n",
    "        self.remove_hooks(handle_list)\n",
    "\n",
    "    def apply_prune(self):\n",
    "        total_original_weights = 0\n",
    "        total_remaining_weights = 0\n",
    "        \n",
    "        for idx, layer in enumerate(self.current_results[\"layer\"]):\n",
    "            current_weight = layer.weight\n",
    "            original_non_zero_weights = torch.sum(current_weight != 0).item()\n",
    "            total_original_weights += original_non_zero_weights\n",
    "            \n",
    "            if torch.sum(current_weight != 0) > torch.numel(current_weight) * self.p:\n",
    "                self.original_results[\"output\"][idx] = self.original_results[\"output\"][idx].to(self.device)\n",
    "                self.current_results[\"output\"][idx] = self.current_results[\"output\"][idx].to(self.device)\n",
    "                self.prune(self.original_results[\"layer\"][idx], layer, self.original_results[\"output\"][idx],\n",
    "                           self.current_results[\"output\"][idx])\n",
    "                self.original_results[\"output\"][idx] = self.original_results[\"output\"][idx].to('cpu')\n",
    "                self.current_results[\"output\"][idx] = self.current_results[\"output\"][idx].to('cpu')\n",
    "\n",
    "            remaining_non_zero_weights = torch.sum(layer.weight != 0).item()\n",
    "            total_remaining_weights += remaining_non_zero_weights\n",
    "\n",
    "            print(f\"Layer {idx} - Original non-zero weights: {original_non_zero_weights}, Remaining non-zero weights: {remaining_non_zero_weights}, Reduction: {original_non_zero_weights - remaining_non_zero_weights}\")\n",
    "            \n",
    "        \n",
    "        print(f\"Total original non-zero weights: {total_original_weights}\")\n",
    "        print(f\"Total remaining non-zero weights: {total_remaining_weights}\")\n",
    "        print(f\"Total reduction: {total_original_weights - total_remaining_weights}\")                \n",
    "\n",
    "\n",
    "def safe_std(tensor, epsilon=None, unbiased=False, dim=None, keepdim=True):\n",
    "    if tensor.numel():\n",
    "        return nanstd(tensor, dim=dim, unbiased=unbiased, keepdim=keepdim)\n",
    "    else:\n",
    "        return torch.tensor(epsilon, dtype=tensor.dtype)\n",
    "\n",
    "\n",
    "def nanstd(tensor, unbiased=False, dim=None, keepdim=True):\n",
    "    mask = torch.isnan(tensor)\n",
    "    n_obs = mask.logical_not().sum(dim=dim, keepdim=keepdim)\n",
    "    mean = torch.nanmean(tensor, dim=dim, keepdim=keepdim)\n",
    "\n",
    "    centered = tensor - mean\n",
    "    centered = centered.masked_fill(mask, 0)\n",
    "    sum_sq = torch.sum(centered ** 2, dim=dim, keepdim=keepdim)\n",
    "\n",
    "    unbiased_factor = torch.where(n_obs > 1, n_obs - 1, n_obs)\n",
    "    var = sum_sq / unbiased_factor\n",
    "\n",
    "    std = torch.sqrt(var)\n",
    "    if not keepdim:\n",
    "        std = std.squeeze(dim)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c91c4b-7e1b-4e2d-be23-8533dcb31db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_remover = WeightRemover(model, device, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c7775-f01a-4958-9a82-41b2fc667599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90117692-80d0-4612-bf19-c5c0341964bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "sequence_length = 10\n",
    "\n",
    "for idx in range(5):\n",
    "    print(f\"-------------{idx} of the ids-------------\")\n",
    "    random_input_ids = torch.tensor(np.random.randint(0, tokenizer.vocab_size, (batch_size, sequence_length)), dtype=torch.long)\n",
    "    random_decoder_input_ids = torch.tensor(np.random.randint(0, tokenizer.vocab_size, (batch_size, sequence_length)), dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        y_ = weight_remover.process(random_input_ids, random_decoder_input_ids)\n",
    "    weight_remover.apply_removal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a396a-a3a5-458b-9aa4-f3a01807a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(ref_model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60fc3f-77fa-4f11-92fd-2e18e00350d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0c1b6-269a-4d91-9138-35ec8f7acd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_weight_data(data):\n",
    "    epochs = []\n",
    "    original_weights = []\n",
    "    remaining_weights = []\n",
    "    reductions = []\n",
    "\n",
    "    pattern = re.compile(r'Total original non-zero weights: (\\d+)\\s+Total remaining non-zero weights: (\\d+)\\s+Total reduction: (\\d+)')\n",
    "    matches = pattern.findall(data)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        epoch = i + 1\n",
    "        original = int(match[0])\n",
    "        remaining = int(match[1])\n",
    "        reduction = int(match[2])\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        original_weights.append(original)\n",
    "        remaining_weights.append(remaining)\n",
    "        reductions.append(reduction)\n",
    "\n",
    "    return epochs, original_weights, remaining_weights, reductions\n",
    "\n",
    "def plot_weight_changes(data):\n",
    "    epochs, original_weights, remaining_weights, reductions = parse_weight_data(data)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, original_weights, label='Original Weights', marker='o')\n",
    "    plt.plot(epochs, remaining_weights, label='Remaining Weights', marker='o')\n",
    "    plt.plot(epochs, reductions, label='Reduction', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Number of Weights')\n",
    "    plt.title('Weight Changes per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24edf4c2-2dd0-494a-8da3-5fc9202fd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../Datasets/Codes/python/train.jsonl'\n",
    "valid_file = '../Datasets/Codes/python/valid.jsonl'\n",
    "test_file = '../Datasets/Codes/python/test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd321e-b27b-4d4e-ae4f-14da3f6e2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_code_snippets(file_path):\n",
    "    code_snippets = []\n",
    "    tokens = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line.strip())\n",
    "            code_snippets.append(data['code_tokens'])\n",
    "            tokens.append(data['docstring_tokens'])\n",
    "    return code_snippets, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f070a5a-f22a-4f4d-9760-970574cc60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snippets, train_tokens = load_code_snippets(train_file)\n",
    "valid_snippets, valid_tokens = load_code_snippets(valid_file)\n",
    "test_snippets, test_tokens = load_code_snippets(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8c951-6666-4761-8b16-13d8fc02e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cc3af-4edc-4655-b921-67a230a49b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snippets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36139aa-eba8-42db-b1d7-94bf83a19c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = ConcernIdentification(ref_model, model, device='cuda:0', p=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da984a6-6c89-480e-9c84-ae7695e52ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (text, tokens) in enumerate(zip(train_snippets, train_tokens)):\n",
    "    print(idx)\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    print(f\"-------------{idx} of the ids-------------\")\n",
    "    random_input_ids = input_ids\n",
    "    random_decoder_input_ids = generated_ids\n",
    "    with torch.no_grad():\n",
    "        y_ = ci.process(text, tokens)\n",
    "    ci.apply_prune()\n",
    "    if idx > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1586bc-f578-4ae9-95a3-33f1e669adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636cddd-ed49-44f7-adde-41dc8df144fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(ref_model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf1f32-913d-4fc3-828e-97eda0f9f95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
