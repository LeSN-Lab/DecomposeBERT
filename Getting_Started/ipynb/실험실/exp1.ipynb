{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f3459d-aaad-4b51-b4c8-4ec84ed5fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1e90f7-63e9-419e-955b-4b8375d0b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utils.helper import ModelConfig, color_print\n",
    "from utils.dataset_utils.load_dataset import (\n",
    "    load_data,\n",
    ")\n",
    "from utils.model_utils.load_model import load_model\n",
    "from utils.model_utils.evaluate import evaluate_model, get_sparsity\n",
    "from utils.dataset_utils.sampling import SamplingDataset\n",
    "from utils.prune_utils.prune import LayerWrapper, find_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb84709-c0dc-4d95-9e00-81ec9b731ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'model_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'YahooAnswersTopics', 'num_labels': 10, 'cache_dir': 'Models'}\n",
      "The model fabriceyhc/bert-base-uncased-yahoo_answers_topics is loaded.\n"
     ]
    }
   ],
   "source": [
    "name = \"YahooAnswersTopics\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = None\n",
    "model_config = ModelConfig(name, device)\n",
    "num_labels = model_config.config[\"num_labels\"]\n",
    "\n",
    "model, tokenizer, checkpoint = load_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbed1822-2f3e-4080-907d-2ebbd56550e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'YahooAnswersTopics', 'path': 'yahoo_answers_topics', 'config_name': 'yahoo_answers_topics', 'text_column': 'question_title', 'label_column': 'topic', 'cache_dir': 'Datasets/Yahoo', 'task_type': 'classification'}\n",
      "Loading cached dataset YahooAnswersTopics.\n",
      "The dataset YahooAnswersTopics is loaded\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    name, batch_size=32, num_workers=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f695c-fff2-4296-bfc4-f60cc5464176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset, Subset\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69333f32-c1a9-4943-a0aa-d3eaf72ae277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 1?\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "validation_dataset = TestDataset(validation_df, tokenizer)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c236bee-89ed-4e0d-8d12-882ae70e3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        self.local_rank = -1  # 단일 GPU 사용을 가정\n",
    "        self.output_mode = \"classification\"  # 또는 \"regression\"에 따라 설정\n",
    "        self.num_labels = model.config.num_labels\n",
    "        self.dont_normalize_importance_by_layer = False\n",
    "        self.dont_normalize_global_importance = False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252ab9d-0ee2-4510-a3f3-589f559fb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    plogp = p * torch.log(p)\n",
    "    plogp[p == 0] = 0\n",
    "    return -plogp.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0dddf-31f9-4787-8d4d-2b9ded4cd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_importance_list = [torch.zeros(12, 12).to(args.device) for _ in range(10)]\n",
    "per_class_token_list=[0.0 for _ in range(10)]\n",
    "multihead_outputs_list = []  # 이 리스트에 각 layer의 출력을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585c6d8-bf87-4a0f-9bf1-f97ac808f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(module, input, output, layer_index):\n",
    "    attention_value, attention_scores = output\n",
    "    attention_value.requires_grad_(True)  # 그래디언트 계산을 위해 requires_grad를 True로 설정\n",
    "    attention_value.retain_grad()\n",
    "    multihead_outputs_list.append(attention_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1da7a5-6970-4a59-91b4-ca2c1d47e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hooks(model):\n",
    "    handles = []  # hook handles를 저장할 리스트\n",
    "    for layer_index, layer in enumerate(model.bert.encoder.layer):\n",
    "        handle = layer.attention.self.register_forward_hook(\n",
    "            partial(hook_fn, layer_index=layer_index)\n",
    "        )\n",
    "        handles.append(handle)  # handle 저장\n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4b04a-9914-49fa-a318-08d239101ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hooks(handles):\n",
    "    for handle in handles:\n",
    "        handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043a0d0-128d-45f8-9625-6f87df93e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = validation_loader  # 또는 validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213bd05-b18d-4ac6-aad6-fbd35668bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_entropy와 compute_importance는 True로 설정하여 기능을 활성화합니다.\n",
    "compute_entropy = True\n",
    "compute_importance = True\n",
    "\n",
    "# 모든 헤드를 사용하여 importance score를 계산합니다.\n",
    "head_mask = None\n",
    "\n",
    "precision_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "recall_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "f1score_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "global_accuracy_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "\n",
    "total_precision_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "total_recall_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "total_f1score_list = [[0 for _ in range(11)] for _ in range(10)]\n",
    "total_global_accuracy_list = [[0 for _ in range(11)] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5e00f-9dd8-4ff4-917d-fa0b79276a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heads_importance(args, model, eval_dataloader, compute_entropy=True, compute_importance=True,\n",
    "                             head_mask=None):\n",
    "    # Prepare our tensors\n",
    "    handles = register_hooks(model)\n",
    "    n_layers, n_heads = model.bert.config.num_hidden_layers, model.bert.config.num_attention_heads\n",
    "    head_importance = torch.zeros(n_layers, n_heads).to(args.device)\n",
    "    each_pred_head_importance = torch.zeros(n_layers, n_heads).to(args.device)\n",
    "    attn_entropy = torch.zeros(n_layers, n_heads).to(args.device)\n",
    "    preds = None\n",
    "    labels = None\n",
    "    tot_tokens = 0.0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        global count\n",
    "        input_ids, label_ids = batch\n",
    "        input_ids = {k: v.squeeze(1).to(device) for k, v in input_ids.items()}\n",
    "        label_ids = label_ids.to(device)\n",
    "        actual_batch_size = input_ids['input_ids'].size(0)\n",
    "\n",
    "        # Do a forward pass (not with torch.no_grad() since we need gradients for importance score - see below)\n",
    "        outputs = model(**input_ids, output_attentions=True)\n",
    "        all_attentions = outputs[1]\n",
    "        logits = outputs[0]\n",
    "\n",
    "        if compute_entropy:\n",
    "            # Update head attention entropy\n",
    "            for layer, attn in enumerate(all_attentions):\n",
    "                masked_entropy = entropy(attn.detach())\n",
    "                attn_entropy[layer] += masked_entropy.sum(-1).sum(0).detach()\n",
    "\n",
    "        if compute_importance:\n",
    "            # Update head importance scores with regards to our loss\n",
    "            # First, backpropagate to populate the gradients\n",
    "            if args.output_mode == \"classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, args.num_labels), label_ids.view(-1))\n",
    "            elif args.output_mode == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            # Second, compute importance scores according to http://arxiv.org/abs/1905.10650\n",
    "            multihead_outputs = multihead_outputs_list\n",
    "            for layer, mh_layer_output in enumerate(multihead_outputs):\n",
    "                # print(layer)\n",
    "                mh_layer_output_store = mh_layer_output\n",
    "                reshaped_mh_layer_output = mh_layer_output_store.view(actual_batch_size, 512, 12, 64)\n",
    "                reshaped_mh_layer_output = reshaped_mh_layer_output.permute(0, 2, 1, 3)\n",
    "\n",
    "                mh_layer_output_grad = mh_layer_output.grad\n",
    "                reshaped_mh_layer_output_grad = mh_layer_output_grad.view(actual_batch_size, 512, 12, 64)\n",
    "                reshaped_mh_layer_output_grad = reshaped_mh_layer_output_grad.permute(0, 2, 1, 3)\n",
    "                dot = torch.einsum(\"bhli,bhli->bhl\", [reshaped_mh_layer_output_grad, reshaped_mh_layer_output])\n",
    "                each_head_importance = dot.abs().sum(-1).sum(0).detach()\n",
    "                head_importance[layer] += each_head_importance\n",
    "                each_pred_head_importance[layer] += each_head_importance\n",
    "            temp_each_pred_head_importance = copy.deepcopy(each_pred_head_importance)\n",
    "            each_pred_head_importance.zero_()\n",
    "            multihead_outputs_list.clear()\n",
    "\n",
    "        # Also store our logits/labels if we want to compute metrics afterwards\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            labels = label_ids.detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            labels = np.append(labels, label_ids.detach().cpu().numpy(), axis=0)\n",
    "        prediction = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "        per_class_importance_list[prediction.item()] += temp_each_pred_head_importance\n",
    "        per_class_token = (input_ids['input_ids'] != 0).float().sum().item()\n",
    "        per_class_token_list[prediction.item()] = per_class_token\n",
    "        tot_tokens += per_class_token\n",
    "\n",
    "    # Normalize\n",
    "    attn_entropy /= tot_tokens\n",
    "    head_importance /= tot_tokens\n",
    "    for i in range(10):\n",
    "        per_class_importance_list[i] /= per_class_token_list[i]\n",
    "\n",
    "    # Layerwise importance normalization\n",
    "    if not args.dont_normalize_importance_by_layer:\n",
    "        exponent = 2\n",
    "        norm_by_layer = torch.pow(torch.pow(head_importance, exponent).sum(-1), 1 / exponent)\n",
    "        head_importance /= norm_by_layer.unsqueeze(-1) + 1e-20\n",
    "        for i in range(10):\n",
    "            norm_by_layer = torch.pow(torch.pow(per_class_importance_list[i], exponent).sum(-1), 1 / exponent)\n",
    "            per_class_importance_list[i] /= norm_by_layer.unsqueeze(-1) + 1e-20\n",
    "\n",
    "    if not args.dont_normalize_global_importance:\n",
    "        head_importance = (head_importance - head_importance.min()) / (head_importance.max() - head_importance.min())\n",
    "        for i in range(10):\n",
    "            per_class_importance_list[i] = (per_class_importance_list[i] - per_class_importance_list[i].min()) / (\n",
    "                        per_class_importance_list[i].max() - per_class_importance_list[i].min())\n",
    "    remove_hooks(handles)\n",
    "    return attn_entropy, head_importance, preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac3a87-d551-423c-80f3-5cd717499e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_heatmap(file_name, array, num_layer, num_heads, label=0):\n",
    "    # tensor를 CPU로 이동하여 numpy 배열로 변환\n",
    "    array = array.cpu().numpy()\n",
    "\n",
    "    df = pd.DataFrame(array)\n",
    "\n",
    "    # 인덱스와 컬럼 이름 설정 (Layer와 Head의 인덱스를 1부터 시작하도록 조정)\n",
    "    df.index = [f\"Layer {i + 1}\" for i in range(num_layer)]\n",
    "    df.columns = [f\"Head {i + 1}\" for i in range(num_heads)]\n",
    "\n",
    "    # 히트맵 생성 및 저장\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Attention Score\n",
    "    sns.heatmap(df, annot=True, fmt=\".2f\", cmap='viridis')\n",
    "    if label == 0 :\n",
    "        plt.title(\"Total head important score\")\n",
    "    else:\n",
    "        plt.title(f'Class {label} head important score')\n",
    "    plt.xlabel('Head')\n",
    "    plt.ylabel('Layer')\n",
    "    plt.savefig(f'./heatmap/head_importance_score/{file_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e93989-8d35-4ac3-bb0e-8aa8d8ab0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_entropy, head_importance, preds, labels = compute_heads_importance(args, model, eval_dataloader, compute_entropy, compute_importance, head_mask)\n",
    "\n",
    "def calculate_prune_head(arr, i):\n",
    "    # 2차원 배열 arr의 모든 요소와 해당 인덱스를 1차원 배열로 변환\n",
    "    flattened_with_indices = [(value, index) for index, value in np.ndenumerate(arr)]\n",
    "\n",
    "    # 값에 따라 오름차순 정렬하여 하위 12개 요소 선택\n",
    "    sorted_by_value = sorted(flattened_with_indices, key=lambda x: x[0])\n",
    "    bottom_12 = sorted_by_value[12 * i:12 * (i + 1)]\n",
    "\n",
    "    # 하위 12개 요소의 인덱스만 추출\n",
    "    bottom_12_indices = [index for _, index in bottom_12]\n",
    "\n",
    "    return bottom_12_indices\n",
    "\n",
    "for i in range(10):\n",
    "    per_class_importance_list[i] = per_class_importance_list[i].cpu().numpy()\n",
    "\n",
    "per_class_head_importance_list = copy.deepcopy(per_class_importance_list)\n",
    "\n",
    "# layer별 max 값을 구함\n",
    "def layer_max(arr):\n",
    "    max_values = np.max(arr, axis=1)\n",
    "    max_index = np.argmax(arr, axis=1)\n",
    "    return max_index\n",
    "\n",
    "def preprocess_prunehead(arr):\n",
    "    for label in range(10):\n",
    "        max_layer = layer_max(per_class_head_importance_list[label])\n",
    "        for layer in range(12):\n",
    "            head = max_layer[layer]\n",
    "            per_class_head_importance_list[label][layer][head] = 100\n",
    "\n",
    "def total_preprocess_prunehead(arr):\n",
    "    max_layer = layer_max(arr)\n",
    "    for layer in range(12):\n",
    "            head = max_layer[layer]\n",
    "            arr[layer][head] = 100\n",
    "    return arr\n",
    "\n",
    "def prune_head(model, prune_list):\n",
    "    for layer_index, head_index in prune_list:\n",
    "        model.bert.encoder.layer[layer_index].attention.prune_heads(([head_index]))\n",
    "    return model\n",
    "\n",
    "def print_prune_head_list(prune_list, trial):\n",
    "    print(f\"total prune number : {len(prune_list)*trial}\")\n",
    "    print(f\"prune head list\")\n",
    "    print(prune_list)\n",
    "\n",
    "\n",
    "def evaluating(model, class_index, prune_num):\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = batch\n",
    "        inputs = {k: v.squeeze(1).to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        prediction = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        preds.extend(prediction.tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "    report = classification_report(true_labels, preds, output_dict=True)\n",
    "    index = str(class_index)\n",
    "    class_report = report[index]\n",
    "    precision_list[class_index][prune_num] = class_report['precision']\n",
    "    recall_list[class_index][prune_num] = class_report['recall']\n",
    "    f1score_list[class_index][prune_num] = class_report['f1-score']\n",
    "    global_accuracy_list[class_index][prune_num] = report['accuracy']\n",
    "\n",
    "    print(f\"Class {class_index} Precision: {class_report['precision']}\")\n",
    "    print(f\"Class {class_index} Recall: {class_report['recall']}\")\n",
    "    print(f\"Class {class_index} F1-Score: {class_report['f1-score']}\")\n",
    "    print(f\"Global Accuracy: {report['accuracy']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631699f2-f3f7-4e4c-8dfe-226a7d1d1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_importance_prunning():\n",
    "  for class_index in range(10):\n",
    "      temp_model = copy.deepcopy(model)\n",
    "      for num in range(11):\n",
    "          print(f'Class {class_index+1} {(num+1)*12} prunning')\n",
    "          prune_list = calculate_prune_head(per_class_head_importance_list[class_index], num)\n",
    "          print_prune_head_list(prune_list, num+1)\n",
    "          temp_model = prune_head(temp_model, prune_list)\n",
    "          evaluating(temp_model, class_index, num)\n",
    "\n",
    "head_importance_prunning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2aea68-ae8e-4b7d-bd23-591872c7ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating_all(model, prune_num):\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = batch\n",
    "        inputs = {k: v.squeeze(1).to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        prediction = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        preds.extend(prediction.tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "    report = classification_report(true_labels, preds, output_dict=True)\n",
    "    for i in range(10):\n",
    "        index = str(i)\n",
    "        class_report = report[index]\n",
    "        total_precision_list[i][prune_num] = class_report['precision']\n",
    "        total_recall_list[i][prune_num] = class_report['recall']\n",
    "        total_f1score_list[i][prune_num] = class_report['f1-score']\n",
    "        total_global_accuracy_list[i][prune_num] = report['accuracy']\n",
    "\n",
    "        print(f\"Class {i} Precision: {class_report['precision']}\")\n",
    "        print(f\"Class {i} Recall: {class_report['recall']}\")\n",
    "        print(f\"Class {i} F1-Score: {class_report['f1-score']}\")\n",
    "        print(f\"Global Accuracy: {report['accuracy']}\")\n",
    "        print()\n",
    "\n",
    "temp_head_importance_score = copy.deepcopy(head_importance).cpu().numpy()\n",
    "temp_head_importance_score = total_preprocess_prunehead(temp_head_importance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c18685-9b3f-4fad-bd1b-98961c0e2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_head_importance_prunning():\n",
    "    temp_model = copy.deepcopy(model)\n",
    "    for num in range(11):\n",
    "        print(f'Total {(num+1)*12} prunning')\n",
    "        prune_list = calculate_prune_head(temp_head_importance_score, num)\n",
    "        print_prune_head_list(prune_list, num+1)\n",
    "        temp_model = prune_head(temp_model, prune_list)\n",
    "        evaluating_all(temp_model, num)\n",
    "\n",
    "total_head_importance_prunning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03adbda3-7ec1-43be-a483-6dfe266ad99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time:14:17:58\n",
      "#Module 0 in progress....\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "color_print(\"Start Time:\" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "color_print(\"#Module \" + str(i) + \" in progress....\")\n",
    "num_samples = 64\n",
    "\n",
    "positive_samples = SamplingDataset(\n",
    "    train_dataloader, i, num_samples, num_labels, True, 4, device=device\n",
    ")\n",
    "negative_samples = SamplingDataset(\n",
    "    train_dataloader, i, num_samples, num_labels, False, 4, device=device\n",
    ")\n",
    "all_samples = SamplingDataset(\n",
    "    train_dataloader, 200, 20, num_labels, False, 4, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "270d82d3-e7dc-4e32-acb3-a992add939f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the original model\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate the original model\")\n",
    "# result = evaluate_model(model, model_config, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0968d6a0-6ef4-4f9b-ac49-9a839fe9208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621b0023-0f0d-4deb-b567-b1cc3077fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prune_utils.prune import prune_magnitude\n",
    "prune_magnitude(\n",
    "    compare, include_layers=[\"attention\", \"intermediate\", \"output\"], sparsity_ratio=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebb2c2e-de2e-42a4-9f74-30d59faa158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prune_utils.prune import prune_concern_identification\n",
    "prune_concern_identification(model, compare, positive_samples, sparsity_ratio=0.5, include_layers=[\"attention\", \"intermediate\",\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ecef414-c3ba-431b-a4a5-ae54d74999e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [11:13<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1742\n",
      "Precision: 0.6665, Recall: 0.6354, F1-Score: 0.6406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.53      6000\n",
      "           1       0.78      0.52      0.63      6000\n",
      "           2       0.76      0.66      0.70      6000\n",
      "           3       0.46      0.54      0.50      6000\n",
      "           4       0.79      0.79      0.79      6000\n",
      "           5       0.94      0.72      0.82      6000\n",
      "           6       0.39      0.47      0.43      6000\n",
      "           7       0.66      0.64      0.65      6000\n",
      "           8       0.50      0.83      0.63      6000\n",
      "           9       0.75      0.72      0.73      6000\n",
      "\n",
      "    accuracy                           0.64     60000\n",
      "   macro avg       0.67      0.64      0.64     60000\n",
      "weighted avg       0.67      0.64      0.64     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_model(compare, model_config, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a7c27f1-e245-4bb3-a424-d117dbccb74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [11:29<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0199\n",
      "Precision: 0.6792, Recall: 0.6760, F1-Score: 0.6742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.56      6000\n",
      "           1       0.74      0.64      0.68      6000\n",
      "           2       0.74      0.73      0.74      6000\n",
      "           3       0.52      0.52      0.52      6000\n",
      "           4       0.80      0.81      0.81      6000\n",
      "           5       0.90      0.82      0.86      6000\n",
      "           6       0.55      0.43      0.48      6000\n",
      "           7       0.64      0.71      0.67      6000\n",
      "           8       0.58      0.81      0.68      6000\n",
      "           9       0.74      0.75      0.74      6000\n",
      "\n",
      "    accuracy                           0.68     60000\n",
      "   macro avg       0.68      0.68      0.67     60000\n",
      "weighted avg       0.68      0.68      0.67     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_model(compare, model_config, test_dataloader)\n",
    "# result = evaluate_model(module, model_config, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "584b8d47-481c-4080-861b-fa07a223dad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39683034509882176,\n",
       " {'bert.encoder.layer.0.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.0.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.0.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.0.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.0.attention.self.value.weight': 0.4001786973741319,\n",
       "  'bert.encoder.layer.0.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.0.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.0.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.0.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.0.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.0.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.0.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.1.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.1.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.1.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.1.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.1.attention.self.value.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.1.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.1.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.1.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.1.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.1.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.1.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.1.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.2.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.2.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.2.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.2.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.2.attention.self.value.weight': 0.4000227186414931,\n",
       "  'bert.encoder.layer.2.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.2.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.2.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.2.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.2.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.2.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.2.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.3.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.3.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.3.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.3.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.3.attention.self.value.weight': 0.4000328911675347,\n",
       "  'bert.encoder.layer.3.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.3.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.3.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.3.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.3.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.3.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.3.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.4.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.4.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.4.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.4.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.4.attention.self.value.weight': 0.4002499050564236,\n",
       "  'bert.encoder.layer.4.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.4.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.4.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.4.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.4.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.4.output.dense.weight': 0.40002526177300346,\n",
       "  'bert.encoder.layer.4.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.5.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.5.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.5.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.5.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.5.attention.self.value.weight': 0.4002600775824653,\n",
       "  'bert.encoder.layer.5.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.5.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.5.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.5.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.5.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.5.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.5.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.6.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.6.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.6.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.6.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.6.attention.self.value.weight': 0.4001956515842014,\n",
       "  'bert.encoder.layer.6.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.6.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.6.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.6.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.6.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.6.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.6.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.7.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.7.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.7.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.7.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.7.attention.self.value.weight': 0.400177001953125,\n",
       "  'bert.encoder.layer.7.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.7.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.7.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.7.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.7.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.7.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.7.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.8.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.8.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.8.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.8.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.8.attention.self.value.weight': 0.4001753065321181,\n",
       "  'bert.encoder.layer.8.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.8.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.8.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.8.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.8.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.8.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.8.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.9.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.9.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.9.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.9.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.9.attention.self.value.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.9.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.9.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.9.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.9.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.9.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.9.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.9.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.10.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.10.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.10.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.10.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.10.attention.self.value.weight': 0.4002838134765625,\n",
       "  'bert.encoder.layer.10.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.10.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.10.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.10.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.10.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.10.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.10.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.11.attention.self.query.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.11.attention.self.query.bias': 0.0,\n",
       "  'bert.encoder.layer.11.attention.self.key.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.11.attention.self.key.bias': 0.0,\n",
       "  'bert.encoder.layer.11.attention.self.value.weight': 0.4001685248480903,\n",
       "  'bert.encoder.layer.11.attention.self.value.bias': 0.0,\n",
       "  'bert.encoder.layer.11.attention.output.dense.weight': 0.4000006781684028,\n",
       "  'bert.encoder.layer.11.attention.output.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.11.intermediate.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.11.intermediate.dense.bias': 0.0,\n",
       "  'bert.encoder.layer.11.output.dense.weight': 0.40000025431315106,\n",
       "  'bert.encoder.layer.11.output.dense.bias': 0.0,\n",
       "  'bert.pooler.dense.weight': 0.0,\n",
       "  'bert.pooler.dense.bias': 0.0,\n",
       "  'classifier.weight': 0.0,\n",
       "  'classifier.bias': 0.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(compare)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
