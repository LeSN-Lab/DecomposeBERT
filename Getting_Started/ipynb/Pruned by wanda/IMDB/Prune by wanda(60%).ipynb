{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1e774c0d-6a12-4e09-83b7-52c6be4f5eea",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"../../../../\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b787f031-cd94-47d7-8f3d-a36a6c772eeb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from utils.helper import ModelConfig, color_print\n",
        "from utils.dataset_utils.load_dataset import (\n",
        "    load_data,\n",
        ")\n",
        "from utils.model_utils.save_module import save_module\n",
        "from utils.model_utils.load_model import load_model\n",
        "from utils.model_utils.evaluate import evaluate_model, get_sparsity, similar\n",
        "from utils.dataset_utils.sampling import SamplingDataset\n",
        "from utils.prune_utils.prune import (\n",
        "    prune_wanda\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e41ca12f-9587-4e99-9e64-895758e0c440",
      "metadata": {},
      "outputs": [],
      "source": [
        "name= \"IMDB\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "checkpoint = None\n",
        "batch_size=16\n",
        "num_workers=4\n",
        "num_samples=4\n",
        "wanda_ratio=0.6\n",
        "seed=44\n",
        "include_layers=[\"attention\", \"intermediate\", \"output\"]\n",
        "exclude_layers=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5bfbe7f-1285-4823-a388-b9f5fd878897",
      "metadata": {},
      "outputs": [],
      "source": [
        "script_start_time = datetime.now()\n",
        "print(f\"Script started at: {script_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d71e362f-ac31-43de-b51f-1cd9a9a388de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the model.\n",
            "{'model_name': 'textattack/bert-base-uncased-imdb', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'IMDB', 'num_labels': 2, 'cache_dir': 'Models'}\n",
            "The model textattack/bert-base-uncased-imdb is loaded.\n"
          ]
        }
      ],
      "source": [
        "model_config = ModelConfig(name, device)\n",
        "num_labels = model_config.config[\"num_labels\"]\n",
        "model, tokenizer, checkpoint = load_model(model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f51b4e6c-5480-42c7-9d62-a05cbd1d4221",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dataset_name': 'IMDB', 'path': 'imdb', 'config_name': 'plain_text', 'text_column': 'text', 'label_column': 'label', 'cache_dir': 'Datasets/IMDB', 'task_type': 'classification'}\n",
            "Loading cached dataset IMDB.\n",
            "The dataset IMDB is loaded\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
        "    name, batch_size=batch_size, num_workers=num_workers, do_cache=True, seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a2a78ba8-1c77-45f0-87f2-90720614723d",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_samples = SamplingDataset(\n",
        "    train_dataloader, 200, num_samples, num_labels, False, 4, device=device, resample=False, seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bccd31bf-6e15-4b28-b96d-cb60a955c037",
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(\"Evaluate the original model\")\n",
        "# result = evaluate_model(model, model_config, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "83d92e9b-8917-4e8d-9a34-71984ff985cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the original model\n",
        "# Evaluating: 100%|?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ| 782/782 [05:36<00:00,  2.32it/s]\n",
        "# Loss: 0.3423\n",
        "# Precision: 0.9306, Recall: 0.9303, F1-Score: 0.9303\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.92      0.94      0.93     12500\n",
        "#            1       0.94      0.92      0.93     12500\n",
        "\n",
        "#     accuracy                           0.93     25000\n",
        "#    macro avg       0.93      0.93      0.93     25000\n",
        "# weighted avg       0.93      0.93      0.93     25000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a6d8bf19-3d3b-4ef7-a3d0-7d89ffb31790",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate the pruned model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ| 782/782 [06:17<00:00,  2.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.5413\n",
            "Precision: 0.8484, Recall: 0.8002, F1-Score: 0.7930\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.99      0.83     12500\n",
            "           1       0.98      0.61      0.75     12500\n",
            "\n",
            "    accuracy                           0.80     25000\n",
            "   macro avg       0.85      0.80      0.79     25000\n",
            "weighted avg       0.85      0.80      0.79     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "module = copy.deepcopy(model)\n",
        "prune_wanda(module, model_config, all_samples, sparsity_ratio=wanda_ratio, include_layers=include_layers, exclude_layers=exclude_layers)\n",
        "print(\"Evaluate the pruned model\")\n",
        "result = evaluate_model(module, model_config, test_dataloader)\n",
        "# save_module(module, \"Modules/\", f\"wanda_{name}_{wanda_ratio}p.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cd3c1423-9a76-4a7d-bec7-aae97284cf65",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (0.6143980203379963, 0.6143980203379963)\n",
            "CCA coefficients mean non-concern: (0.6183148282163826, 0.6183148282163826)\n",
            "Linear CKA concern: 0.6486981867761101\n",
            "Linear CKA non-concern: 0.4212675814172706\n",
            "Kernel CKA concern: 0.6009467774142722\n",
            "Kernel CKA non-concern: 0.396529098516069\n"
          ]
        }
      ],
      "source": [
        "for concern in range(num_labels):\n",
        "    print(f\"--{concern}--\")\n",
        "    positive_samples = SamplingDataset(\n",
        "        train_dataloader, concern, num_samples, num_labels, True, 4, device=device, resample=False, seed=seed\n",
        "    )\n",
        "    negative_samples = SamplingDataset(\n",
        "        train_dataloader, concern, num_samples, num_labels, False, 4, device=device, resample=False, seed=seed\n",
        "    )\n",
        "    similar(model, module, valid_dataloader, concern, num_samples, num_labels, device=device, seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5163bd33-5b99-487b-9099-ea53b46eaacd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5945582120163211,\n",
              " {'bert.encoder.layer.0.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.0.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.0.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.0.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.0.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.0.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.0.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.0.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.0.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.0.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.0.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.0.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.1.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.1.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.1.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.1.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.1.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.1.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.1.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.1.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.1.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.1.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.1.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.1.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.2.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.2.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.2.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.2.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.2.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.2.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.2.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.2.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.2.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.2.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.2.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.2.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.3.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.3.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.3.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.3.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.3.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.3.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.3.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.3.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.3.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.3.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.3.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.3.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.4.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.4.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.4.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.4.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.4.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.4.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.4.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.4.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.4.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.4.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.4.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.4.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.5.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.5.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.5.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.5.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.5.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.5.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.5.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.5.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.5.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.5.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.5.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.5.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.6.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.6.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.6.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.6.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.6.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.6.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.6.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.6.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.6.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.6.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.6.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.6.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.7.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.7.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.7.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.7.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.7.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.7.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.7.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.7.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.7.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.7.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.7.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.7.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.8.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.8.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.8.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.8.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.8.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.8.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.8.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.8.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.8.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.8.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.8.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.8.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.9.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.9.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.9.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.9.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.9.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.9.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.9.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.9.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.9.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.9.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.9.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.9.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.10.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.10.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.10.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.10.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.10.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.10.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.10.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.10.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.10.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.10.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.10.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.10.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.11.attention.self.query.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.11.attention.self.query.bias': 0.0,\n",
              "  'bert.encoder.layer.11.attention.self.key.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.11.attention.self.key.bias': 0.0,\n",
              "  'bert.encoder.layer.11.attention.self.value.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.11.attention.self.value.bias': 0.0,\n",
              "  'bert.encoder.layer.11.attention.output.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.11.attention.output.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.11.intermediate.dense.weight': 0.5989583333333334,\n",
              "  'bert.encoder.layer.11.intermediate.dense.bias': 0.0,\n",
              "  'bert.encoder.layer.11.output.dense.weight': 0.5999348958333334,\n",
              "  'bert.encoder.layer.11.output.dense.bias': 0.0,\n",
              "  'bert.pooler.dense.weight': 0.0,\n",
              "  'bert.pooler.dense.bias': 0.0,\n",
              "  'classifier.weight': 0.0,\n",
              "  'classifier.bias': 0.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_sparsity(module)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}