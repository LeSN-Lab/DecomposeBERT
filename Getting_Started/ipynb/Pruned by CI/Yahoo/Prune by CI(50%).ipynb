{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f3459d-aaad-4b51-b4c8-4ec84ed5fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1e90f7-63e9-419e-955b-4b8375d0b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utils.helper import ModelConfig, color_print\n",
    "from utils.dataset_utils.load_dataset import (\n",
    "    load_data,\n",
    ")\n",
    "from utils.model_utils.load_model import load_model\n",
    "from utils.model_utils.save_module import save_module\n",
    "from utils.model_utils.evaluate import evaluate_model, get_sparsity, similar\n",
    "from utils.dataset_utils.sampling import SamplingDataset\n",
    "from utils.prune_utils.prune import (\n",
    "    prune_concern_identification,\n",
    "    recover_tangling_identification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1362c6b-9864-4304-9738-577a2e695918",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"YahooAnswersTopics\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size=16\n",
    "num_workers=4\n",
    "num_samples=4\n",
    "ci_ratio=0.5\n",
    "seed=44\n",
    "include_layers=[\"attention\", \"intermediate\", \"output\"]\n",
    "exclude_layers=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb807b34-e46a-42c7-8330-b3a91956a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_start_time = datetime.now()\n",
    "print(f\"Script started at: {script_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd934130-953b-4ea6-b607-28213f803299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'model_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'YahooAnswersTopics', 'num_labels': 10, 'cache_dir': 'Models'}\n",
      "The model fabriceyhc/bert-base-uncased-yahoo_answers_topics is loaded.\n"
     ]
    }
   ],
   "source": [
    "model_config = ModelConfig(name, device)\n",
    "num_labels = model_config.config[\"num_labels\"]\n",
    "model, tokenizer, checkpoint = load_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570bb960-f2fb-4eca-bf55-7963c144af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluate the original model\")\n",
    "# result = evaluate_model(model, model_config, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf059d8-34b1-4497-af84-ddf8732de9b1",
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793a48a1-206d-4f4e-9149-eb88d53f5f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'YahooAnswersTopics', 'path': 'yahoo_answers_topics', 'config_name': 'yahoo_answers_topics', 'text_column': 'question_title', 'label_column': 'topic', 'cache_dir': 'Datasets/Yahoo', 'task_type': 'classification'}\n",
      "Loading cached dataset YahooAnswersTopics.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "Evaluate the pruned model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|?��?��?��?��?��?��?��?��?��?��| 1875/1875 [15:36<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1605\n",
      "Precision: 0.6613, Recall: 0.6402, F1-Score: 0.6417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55      6000\n",
      "           1       0.77      0.53      0.63      6000\n",
      "           2       0.74      0.69      0.71      6000\n",
      "           3       0.53      0.45      0.48      6000\n",
      "           4       0.79      0.79      0.79      6000\n",
      "           5       0.93      0.72      0.82      6000\n",
      "           6       0.48      0.42      0.45      6000\n",
      "           7       0.46      0.78      0.58      6000\n",
      "           8       0.61      0.77      0.68      6000\n",
      "           9       0.74      0.71      0.73      6000\n",
      "\n",
      "    accuracy                           0.64     60000\n",
      "   macro avg       0.66      0.64      0.64     60000\n",
      "weighted avg       0.66      0.64      0.64     60000\n",
      "\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: (0.7596808225789226, 0.7596808225789226)\n",
      "CCA coefficients mean non-concern: (0.7536513437828456, 0.7536513437828456)\n",
      "Linear CKA concern: 0.8806723154179579\n",
      "Linear CKA non-concern: 0.8429091819501311\n",
      "Kernel CKA concern: 0.8001038850162547\n",
      "Kernel CKA non-concern: 0.7370235047026101\n",
      "{'dataset_name': 'YahooAnswersTopics', 'path': 'yahoo_answers_topics', 'config_name': 'yahoo_answers_topics', 'text_column': 'question_title', 'label_column': 'topic', 'cache_dir': 'Datasets/Yahoo', 'task_type': 'classification'}\n",
      "Loading cached dataset YahooAnswersTopics.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "Evaluate the pruned model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|?��?��        | 260/1875 [02:04<12:54,  2.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 28\u001B[0m\n\u001B[1;32m     18\u001B[0m prune_concern_identification(\n\u001B[1;32m     19\u001B[0m     module,\n\u001B[1;32m     20\u001B[0m     model_config,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m     sparsity_ratio\u001B[38;5;241m=\u001B[39mci_ratio,\n\u001B[1;32m     25\u001B[0m )\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluate the pruned model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconcern\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m get_sparsity(module)\n\u001B[1;32m     31\u001B[0m similar(model, module, valid_dataloader, concern, num_samples, num_labels, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/LESN/Decompose/DecomposeTransformer/Getting_Started/ipynb/Pruned by CI/Yahoo/../../../../utils/model_utils/evaluate.py:46\u001B[0m, in \u001B[0;36mevaluate_model\u001B[0;34m(model, model_config, test_dataloader, is_binary)\u001B[0m\n\u001B[1;32m     43\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(logits, labels)\n\u001B[1;32m     44\u001B[0m pred \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 46\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m all_preds\u001B[38;5;241m.\u001B[39mextend(pred\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     48\u001B[0m all_labels\u001B[38;5;241m.\u001B[39mextend(labels\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for concern in range(num_labels):\n",
    "    train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    name, batch_size=batch_size, num_workers=num_workers, do_cache=True\n",
    "    )\n",
    "    \n",
    "    positive_samples = SamplingDataset(\n",
    "        train_dataloader, concern, num_samples, num_labels, True, 4, device=device, resample=False, seed=seed\n",
    "    )\n",
    "    negative_samples = SamplingDataset(\n",
    "        train_dataloader, concern, num_samples, num_labels, False, 4, device=device, resample=False, seed=seed\n",
    "    )\n",
    "    all_samples = SamplingDataset(\n",
    "        train_dataloader, 200, num_samples, num_labels, False, 4, device=device, resample=False, seed=seed\n",
    "    )\n",
    "    \n",
    "    module = copy.deepcopy(model)\n",
    "    \n",
    "    prune_concern_identification(\n",
    "        module,\n",
    "        model_config,\n",
    "        positive_samples,\n",
    "        negative_samples,\n",
    "        include_layers=include_layers,\n",
    "        exclude_layers=exclude_layers,\n",
    "        sparsity_ratio=ci_ratio,\n",
    "    )\n",
    "    \n",
    "    print(f\"Evaluate the pruned model {concern}\")\n",
    "    result = evaluate_model(module, model_config, test_dataloader)\n",
    "    get_sparsity(module)\n",
    "    \n",
    "    similar(model, module, valid_dataloader, concern, num_samples, num_labels, device=device, seed=seed)\n",
    "    \n",
    "    # save_module(module, \"Modules/\", f\"ci_{name}_{ci_ratio}p.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
