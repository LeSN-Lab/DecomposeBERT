{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f3459d-aaad-4b51-b4c8-4ec84ed5fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1e90f7-63e9-419e-955b-4b8375d0b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utils.helper import ModelConfig, color_print\n",
    "from utils.dataset_utils.load_dataset import (\n",
    "    load_data,\n",
    ")\n",
    "from utils.model_utils.load_model import load_model\n",
    "from utils.model_utils.save_module import save_module\n",
    "from utils.model_utils.evaluate import evaluate_model, get_sparsity, similar\n",
    "from utils.dataset_utils.sampling import SamplingDataset\n",
    "from utils.prune_utils.prune import (\n",
    "    prune_concern_identification,\n",
    "    recover_tangling_identification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1362c6b-9864-4304-9738-577a2e695918",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"YahooAnswersTopics\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size=16\n",
    "num_workers=4\n",
    "num_samples=4\n",
    "ci_ratio=0.6\n",
    "seed=44\n",
    "include_layers=[\"attention\", \"intermediate\", \"output\"]\n",
    "exclude_layers=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67871c2a-7bde-4337-b3ed-bdb5118791cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_start_time = datetime.now()\n",
    "print(f\"Script started at: {script_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd934130-953b-4ea6-b607-28213f803299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'model_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'YahooAnswersTopics', 'num_labels': 10, 'cache_dir': 'Models'}\n",
      "The model fabriceyhc/bert-base-uncased-yahoo_answers_topics is loaded.\n"
     ]
    }
   ],
   "source": [
    "model_config = ModelConfig(name, device)\n",
    "num_labels = model_config.config[\"num_labels\"]\n",
    "model, tokenizer, checkpoint = load_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570bb960-f2fb-4eca-bf55-7963c144af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluate the original model\")\n",
    "# result = evaluate_model(model, model_config, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf059d8-34b1-4497-af84-ddf8732de9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the original model\n",
    "# Evaluating: 100%|?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ| 1875/1875 [30:03<00:00,  1.04it/s]\n",
    "# Loss: 1.0044\n",
    "# Precision: 0.6874, Recall: 0.6865, F1-Score: 0.6839\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.57      0.57      0.57      6000\n",
    "#            1       0.74      0.66      0.69      6000\n",
    "#            2       0.71      0.78      0.74      6000\n",
    "#            3       0.54      0.53      0.53      6000\n",
    "#            4       0.80      0.82      0.81      6000\n",
    "#            5       0.90      0.84      0.87      6000\n",
    "#            6       0.61      0.43      0.50      6000\n",
    "#            7       0.62      0.73      0.67      6000\n",
    "#            8       0.64      0.76      0.70      6000\n",
    "#            9       0.75      0.75      0.75      6000\n",
    "\n",
    "#     accuracy                           0.69     60000\n",
    "#    macro avg       0.69      0.69      0.68     60000\n",
    "# weighted avg       0.69      0.69      0.68     60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793a48a1-206d-4f4e-9149-eb88d53f5f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'YahooAnswersTopics', 'path': 'yahoo_answers_topics', 'config_name': 'yahoo_answers_topics', 'text_column': 'question_title', 'label_column': 'topic', 'cache_dir': 'Datasets/Yahoo', 'task_type': 'classification'}\n",
      "Loading cached dataset YahooAnswersTopics.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "Evaluate the pruned model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ?–ˆ| 1875/1875 [09:33<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6013\n",
      "Precision: 0.6412, Recall: 0.5282, F1-Score: 0.5343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51      6000\n",
      "           1       0.82      0.33      0.47      6000\n",
      "           2       0.84      0.37      0.51      6000\n",
      "           3       0.53      0.27      0.36      6000\n",
      "           4       0.63      0.80      0.70      6000\n",
      "           5       0.96      0.54      0.69      6000\n",
      "           6       0.46      0.35      0.40      6000\n",
      "           7       0.27      0.85      0.41      6000\n",
      "           8       0.56      0.74      0.64      6000\n",
      "           9       0.80      0.54      0.65      6000\n",
      "\n",
      "    accuracy                           0.53     60000\n",
      "   macro avg       0.64      0.53      0.53     60000\n",
      "weighted avg       0.64      0.53      0.53     60000\n",
      "\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: (0.7011195734000673, 0.7011195734000673)\n",
      "CCA coefficients mean non-concern: (0.6948876010481285, 0.6948876010481285)\n",
      "Linear CKA concern: 0.7192087625423697\n",
      "Linear CKA non-concern: 0.683800615113059\n",
      "Kernel CKA concern: 0.4968525404372729\n",
      "Kernel CKA non-concern: 0.4176894665179076\n",
      "{'dataset_name': 'YahooAnswersTopics', 'path': 'yahoo_answers_topics', 'config_name': 'yahoo_answers_topics', 'text_column': 'question_title', 'label_column': 'topic', 'cache_dir': 'Datasets/Yahoo', 'task_type': 'classification'}\n",
      "Loading cached dataset YahooAnswersTopics.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m concern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_labels):\n\u001b[0;32m----> 2\u001b[0m     train_dataloader, valid_dataloader, test_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     positive_samples \u001b[38;5;241m=\u001b[39m SamplingDataset(\n\u001b[1;32m      7\u001b[0m         train_dataloader, concern, num_samples, num_labels, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m4\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     negative_samples \u001b[38;5;241m=\u001b[39m SamplingDataset(\n\u001b[1;32m     10\u001b[0m         train_dataloader, concern, num_samples, num_labels, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m4\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     11\u001b[0m     )\n",
      "File \u001b[0;32m~/LESN/Decompose/DecomposeTransformer/Getting_Started/ipynb/Pruned by CI/Yahoo/../../../../utils/dataset_utils/load_dataset.py:141\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(dataset_name, batch_size, valid_size, num_workers, pin_memory, seed, do_cache)\u001b[0m\n\u001b[1;32m    130\u001b[0m data_config \u001b[38;5;241m=\u001b[39m DataConfig(\n\u001b[1;32m    131\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m    132\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     do_cache\u001b[38;5;241m=\u001b[39mdo_cache,\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    140\u001b[0m data_config\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_cached_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LESN/Decompose/DecomposeTransformer/Getting_Started/ipynb/Pruned by CI/Yahoo/../../../../utils/dataset_utils/load_dataset.py:122\u001b[0m, in \u001b[0;36mload_cached_dataset\u001b[0;34m(data_config)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     color_print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading cached dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_config\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     valid_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(join(cached_dataset_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    124\u001b[0m     test_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(join(cached_dataset_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/DecomposeTransformer/lib/python3.8/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/DecomposeTransformer/lib/python3.8/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/DecomposeTransformer/lib/python3.8/site-packages/torch/serialization.py:1416\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1416\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.conda/envs/DecomposeTransformer/lib/python3.8/site-packages/torch/serialization.py:1381\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1381\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for concern in range(num_labels):\n",
    "    train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    name, batch_size=batch_size, num_workers=num_workers, do_cache=True\n",
    "    )\n",
    "    \n",
    "    positive_samples = SamplingDataset(\n",
    "        train_dataloader, concern, num_samples, num_labels, True, 4, device=device, resample=False, seed=seed\n",
    "    )\n",
    "    negative_samples = SamplingDataset(\n",
    "        train_dataloader, concern, num_samples, num_labels, False, 4, device=device, resample=False, seed=seed\n",
    "    )\n",
    "    all_samples = SamplingDataset(\n",
    "        train_dataloader, 200, num_samples, num_labels, False, 4, device=device, resample=False, seed=seed\n",
    "    )\n",
    "    \n",
    "    module = copy.deepcopy(model)\n",
    "    \n",
    "    prune_concern_identification(\n",
    "        module,\n",
    "        model_config,\n",
    "        positive_samples,\n",
    "        negative_samples,\n",
    "        include_layers=include_layers,\n",
    "        exclude_layers=exclude_layers,\n",
    "        sparsity_ratio=ci_ratio,\n",
    "    )\n",
    "    \n",
    "    print(f\"Evaluate the pruned model {concern}\")\n",
    "    result = evaluate_model(module, model_config, test_dataloader)\n",
    "    get_sparsity(module)\n",
    "    \n",
    "    similar(model, module, valid_dataloader, concern, num_samples, num_labels, device=device, seed=seed)\n",
    "    \n",
    "    # save_module(module, \"Modules/\", f\"ci_{name}_{ci_ratio}p.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
