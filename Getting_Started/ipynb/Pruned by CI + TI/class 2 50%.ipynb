{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1818882-7b01-4101-9fe4-35050d9ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc98c034-af69-4d41-b117-40c6db3b491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utils.helper import ModelConfig, color_print\n",
    "from utils.dataset_utils.load_dataset import (\n",
    "    load_data,\n",
    "    convert_dataset_labels_to_binary,\n",
    ")\n",
    "from utils.model_utils.load_model import load_model\n",
    "from utils.model_utils.evaluate import evaluate_model, get_sparsity\n",
    "from utils.model_utils.save_module import save_module\n",
    "from utils.decompose_utils.weight_remover import WeightRemoverBert\n",
    "from utils.decompose_utils.concern_identification import ConcernIdentificationBert\n",
    "from utils.decompose_utils.tangling_identification import TanglingIdentification\n",
    "from utils.decompose_utils.concern_modularization import ConcernModularizationBert\n",
    "from utils.decompose_utils.sampling import sampling_class\n",
    "from utils.prune_utils.prune import prune_magnitude, find_layers, LayerWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0bbc4ff-e11f-418f-acca-bcd53095c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_concern_identification(\n",
    "    model,\n",
    "    module,\n",
    "    dataloader,\n",
    "    sparsity_ratio=0.4,\n",
    "    p=1,\n",
    "    include_layers=None,\n",
    "    exclude_layers=None,\n",
    "):\n",
    "    ref_layers = find_layers(\n",
    "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    target_layers = find_layers(\n",
    "        module, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    wrappers = {}\n",
    "    ref_handle_list = []\n",
    "    target_handle_list = []\n",
    "\n",
    "    def get_hook(wrapper):\n",
    "        def hook(module, input, output):\n",
    "            wrapper.update(input, output)\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for (ref_name, ref_layer), (target_name, target_layer) in zip(\n",
    "        ref_layers.items(), target_layers.items()\n",
    "    ):\n",
    "        ref_wrapper = LayerWrapper(ref_name, ref_layer)\n",
    "        target_wrapper = LayerWrapper(target_name, target_layer)\n",
    "\n",
    "        wrappers[ref_name] = {\"ref\": ref_wrapper, \"target\": target_wrapper}\n",
    "\n",
    "        ref_handle = ref_layer.register_forward_hook(get_hook(ref_wrapper))\n",
    "        target_handle = target_layer.register_forward_hook(get_hook(target_wrapper))\n",
    "\n",
    "        ref_handle_list.append(ref_handle)\n",
    "        target_handle_list.append(target_handle)\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids, attn_mask, _, _ = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_ids, attention_mask=attn_mask)\n",
    "            module(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "    for handle in ref_handle_list + target_handle_list:\n",
    "        handle.remove()\n",
    "\n",
    "    for name, wrapper_pair in wrappers.items():\n",
    "        wrapper_pair[\"ref\"].update_batch()\n",
    "        wrapper_pair[\"target\"].update_batch()\n",
    "\n",
    "        ref_outputs = wrapper_pair[\"ref\"].outputs\n",
    "        target_outputs = wrapper_pair[\"target\"].outputs\n",
    "\n",
    "        current_weight = wrapper_pair[\"target\"].layer.weight.data\n",
    "        original_weight = wrapper_pair[\"ref\"].layer.weight.data\n",
    "\n",
    "        # output_loss = (target_outputs - ref_outputs) ** 2\n",
    "        output_loss = target_outputs - ref_outputs  # (batch_size, seq_dim, output_dim)\n",
    "\n",
    "        # Normalize batch size\n",
    "        # if p == 'mean':\n",
    "        #     output_loss = torch.mean(output_loss, dim=0)\n",
    "        # elif p == 1:\n",
    "        #     output_loss = torch.norm(output_loss, p=1, dim=0)\n",
    "        # elif p == 2:\n",
    "        #     output_loss = torch.norm(output_loss, p=2, dim=0)\n",
    "        # elif p == \"inf\":\n",
    "        #     output_loss = torch.norm(output_loss, p=float('inf'), dim=0)\n",
    "        # else:\n",
    "        #     raise ValueError(\"Unsupported norm type\")\n",
    "\n",
    "        # Normalize output_loss\n",
    "        # output_loss = (output_loss - output_loss.mean(dim=0)) /output_loss.std(dim=0)\n",
    "\n",
    "        # weight_score = torch.mean(output_loss, dim=0).reshape(-1, 1).to(device)\n",
    "        output_loss_flat = output_loss.to(device).view(\n",
    "            -1, output_loss.size(-1)\n",
    "        )  # (batch_size * seq_dim, output_dim)\n",
    "\n",
    "        inputs = wrapper_pair[\"target\"].inputs  # (batch_size, seq_dim, input_dim)\n",
    "        inputs_flat = inputs.view(\n",
    "            -1, inputs.size(-1)\n",
    "        )  # (batch_size * seq_dim, input_dim)\n",
    "        inverse_inputs = torch.linalg.pinv(inputs_flat).to(\n",
    "            device\n",
    "        )  # (input_dim, batch_size * seq_dim)\n",
    "        pseudo_weight_matrix = torch.matmul(\n",
    "            inverse_inputs, output_loss_flat\n",
    "        )  # (input_dim, output_dim)\n",
    "\n",
    "        importance_score = torch.abs(\n",
    "            pseudo_weight_matrix.T * current_weight\n",
    "        )  # (output_dim, input_dim)\n",
    "\n",
    "        W_mask = torch.zeros_like(importance_score) == 1\n",
    "        sort_res = torch.sort(importance_score, dim=-1, stable=True)\n",
    "        indices = sort_res[1][:, : int(importance_score.shape[1] * sparsity_ratio)]\n",
    "        W_mask.scatter_(1, indices, True)\n",
    "        current_weight[W_mask] = 0\n",
    "\n",
    "        # importance_score = importance_score.reshape(-1)\n",
    "        # W_mask = (torch.zeros_like(importance_score) == 1)\n",
    "        # sort_res = torch.sort(importance_score, stable=True)\n",
    "        # indices = sort_res[1][:int(importance_score.shape[0] * sparsity_ratio)]\n",
    "        # W_mask.scatter_(0, indices, True)\n",
    "        # W_mask = W_mask.view_as(current_weight)\n",
    "        # current_weight[W_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6093a85-4bc7-47d0-b2bb-0cafbfba0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"OSDG\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = None\n",
    "model_config = ModelConfig(name, device)\n",
    "num_labels = model_config.config[\"num_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0ac679-8132-4a34-a818-940ed3c19a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'model_name': 'sadickam/sdg-classification-bert', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'OSDG', 'num_labels': 16, 'cache_dir': 'Models'}\n",
      "The model sadickam/sdg-classification-bert is loaded.\n",
      "{'dataset_name': 'OSDG', 'path': 'albertmartinez/OSDG', 'config_name': '2024-01-01', 'text_column': 'text', 'label_column': 'labels', 'cache_dir': 'Datasets/OSDG', 'task_type': 'classification'}\n",
      "Loading cached dataset OSDG.\n",
      "The dataset OSDG is loaded\n",
      "Start Time:01:18:59\n",
      "#Module 2 in progress....\n",
      "origin\n",
      "Start Magnitude pruning\n",
      "0.09990180388583593\n",
      "Start Positive CI after sparse\n",
      "(0.49669810368769646, {'bert.encoder.layer.0.attention.self.query.weight': 0.5, 'bert.encoder.layer.0.attention.self.query.bias': 0.0, 'bert.encoder.layer.0.attention.self.key.weight': 0.5, 'bert.encoder.layer.0.attention.self.key.bias': 0.0, 'bert.encoder.layer.0.attention.self.value.weight': 0.5, 'bert.encoder.layer.0.attention.self.value.bias': 0.0, 'bert.encoder.layer.0.attention.output.dense.weight': 0.5, 'bert.encoder.layer.0.attention.output.dense.bias': 0.0, 'bert.encoder.layer.0.intermediate.dense.weight': 0.5, 'bert.encoder.layer.0.intermediate.dense.bias': 0.0, 'bert.encoder.layer.0.output.dense.weight': 0.5, 'bert.encoder.layer.0.output.dense.bias': 0.0, 'bert.encoder.layer.1.attention.self.query.weight': 0.5, 'bert.encoder.layer.1.attention.self.query.bias': 0.0, 'bert.encoder.layer.1.attention.self.key.weight': 0.5, 'bert.encoder.layer.1.attention.self.key.bias': 0.0, 'bert.encoder.layer.1.attention.self.value.weight': 0.5, 'bert.encoder.layer.1.attention.self.value.bias': 0.0, 'bert.encoder.layer.1.attention.output.dense.weight': 0.5, 'bert.encoder.layer.1.attention.output.dense.bias': 0.0, 'bert.encoder.layer.1.intermediate.dense.weight': 0.5, 'bert.encoder.layer.1.intermediate.dense.bias': 0.0, 'bert.encoder.layer.1.output.dense.weight': 0.5, 'bert.encoder.layer.1.output.dense.bias': 0.0, 'bert.encoder.layer.2.attention.self.query.weight': 0.5, 'bert.encoder.layer.2.attention.self.query.bias': 0.0, 'bert.encoder.layer.2.attention.self.key.weight': 0.5, 'bert.encoder.layer.2.attention.self.key.bias': 0.0, 'bert.encoder.layer.2.attention.self.value.weight': 0.5, 'bert.encoder.layer.2.attention.self.value.bias': 0.0, 'bert.encoder.layer.2.attention.output.dense.weight': 0.5, 'bert.encoder.layer.2.attention.output.dense.bias': 0.0, 'bert.encoder.layer.2.intermediate.dense.weight': 0.5, 'bert.encoder.layer.2.intermediate.dense.bias': 0.0, 'bert.encoder.layer.2.output.dense.weight': 0.5, 'bert.encoder.layer.2.output.dense.bias': 0.0, 'bert.encoder.layer.3.attention.self.query.weight': 0.5, 'bert.encoder.layer.3.attention.self.query.bias': 0.0, 'bert.encoder.layer.3.attention.self.key.weight': 0.5, 'bert.encoder.layer.3.attention.self.key.bias': 0.0, 'bert.encoder.layer.3.attention.self.value.weight': 0.5, 'bert.encoder.layer.3.attention.self.value.bias': 0.0, 'bert.encoder.layer.3.attention.output.dense.weight': 0.5, 'bert.encoder.layer.3.attention.output.dense.bias': 0.0, 'bert.encoder.layer.3.intermediate.dense.weight': 0.5, 'bert.encoder.layer.3.intermediate.dense.bias': 0.0, 'bert.encoder.layer.3.output.dense.weight': 0.5, 'bert.encoder.layer.3.output.dense.bias': 0.0, 'bert.encoder.layer.4.attention.self.query.weight': 0.5, 'bert.encoder.layer.4.attention.self.query.bias': 0.0, 'bert.encoder.layer.4.attention.self.key.weight': 0.5, 'bert.encoder.layer.4.attention.self.key.bias': 0.0, 'bert.encoder.layer.4.attention.self.value.weight': 0.5, 'bert.encoder.layer.4.attention.self.value.bias': 0.0, 'bert.encoder.layer.4.attention.output.dense.weight': 0.5, 'bert.encoder.layer.4.attention.output.dense.bias': 0.0, 'bert.encoder.layer.4.intermediate.dense.weight': 0.5, 'bert.encoder.layer.4.intermediate.dense.bias': 0.0, 'bert.encoder.layer.4.output.dense.weight': 0.5, 'bert.encoder.layer.4.output.dense.bias': 0.0, 'bert.encoder.layer.5.attention.self.query.weight': 0.5, 'bert.encoder.layer.5.attention.self.query.bias': 0.0, 'bert.encoder.layer.5.attention.self.key.weight': 0.5, 'bert.encoder.layer.5.attention.self.key.bias': 0.0, 'bert.encoder.layer.5.attention.self.value.weight': 0.5, 'bert.encoder.layer.5.attention.self.value.bias': 0.0, 'bert.encoder.layer.5.attention.output.dense.weight': 0.5, 'bert.encoder.layer.5.attention.output.dense.bias': 0.0, 'bert.encoder.layer.5.intermediate.dense.weight': 0.5, 'bert.encoder.layer.5.intermediate.dense.bias': 0.0, 'bert.encoder.layer.5.output.dense.weight': 0.5, 'bert.encoder.layer.5.output.dense.bias': 0.0, 'bert.encoder.layer.6.attention.self.query.weight': 0.5, 'bert.encoder.layer.6.attention.self.query.bias': 0.0, 'bert.encoder.layer.6.attention.self.key.weight': 0.5, 'bert.encoder.layer.6.attention.self.key.bias': 0.0, 'bert.encoder.layer.6.attention.self.value.weight': 0.5, 'bert.encoder.layer.6.attention.self.value.bias': 0.0, 'bert.encoder.layer.6.attention.output.dense.weight': 0.5, 'bert.encoder.layer.6.attention.output.dense.bias': 0.0, 'bert.encoder.layer.6.intermediate.dense.weight': 0.5, 'bert.encoder.layer.6.intermediate.dense.bias': 0.0, 'bert.encoder.layer.6.output.dense.weight': 0.5, 'bert.encoder.layer.6.output.dense.bias': 0.0, 'bert.encoder.layer.7.attention.self.query.weight': 0.5, 'bert.encoder.layer.7.attention.self.query.bias': 0.0, 'bert.encoder.layer.7.attention.self.key.weight': 0.5, 'bert.encoder.layer.7.attention.self.key.bias': 0.0, 'bert.encoder.layer.7.attention.self.value.weight': 0.5, 'bert.encoder.layer.7.attention.self.value.bias': 0.0, 'bert.encoder.layer.7.attention.output.dense.weight': 0.5, 'bert.encoder.layer.7.attention.output.dense.bias': 0.0, 'bert.encoder.layer.7.intermediate.dense.weight': 0.5, 'bert.encoder.layer.7.intermediate.dense.bias': 0.0, 'bert.encoder.layer.7.output.dense.weight': 0.5, 'bert.encoder.layer.7.output.dense.bias': 0.0, 'bert.encoder.layer.8.attention.self.query.weight': 0.5, 'bert.encoder.layer.8.attention.self.query.bias': 0.0, 'bert.encoder.layer.8.attention.self.key.weight': 0.5, 'bert.encoder.layer.8.attention.self.key.bias': 0.0, 'bert.encoder.layer.8.attention.self.value.weight': 0.5, 'bert.encoder.layer.8.attention.self.value.bias': 0.0, 'bert.encoder.layer.8.attention.output.dense.weight': 0.5, 'bert.encoder.layer.8.attention.output.dense.bias': 0.0, 'bert.encoder.layer.8.intermediate.dense.weight': 0.5, 'bert.encoder.layer.8.intermediate.dense.bias': 0.0, 'bert.encoder.layer.8.output.dense.weight': 0.5, 'bert.encoder.layer.8.output.dense.bias': 0.0, 'bert.encoder.layer.9.attention.self.query.weight': 0.5, 'bert.encoder.layer.9.attention.self.query.bias': 0.0, 'bert.encoder.layer.9.attention.self.key.weight': 0.5, 'bert.encoder.layer.9.attention.self.key.bias': 0.0, 'bert.encoder.layer.9.attention.self.value.weight': 0.5, 'bert.encoder.layer.9.attention.self.value.bias': 0.0, 'bert.encoder.layer.9.attention.output.dense.weight': 0.5, 'bert.encoder.layer.9.attention.output.dense.bias': 0.0, 'bert.encoder.layer.9.intermediate.dense.weight': 0.5, 'bert.encoder.layer.9.intermediate.dense.bias': 0.0, 'bert.encoder.layer.9.output.dense.weight': 0.5, 'bert.encoder.layer.9.output.dense.bias': 0.0, 'bert.encoder.layer.10.attention.self.query.weight': 0.5, 'bert.encoder.layer.10.attention.self.query.bias': 0.0, 'bert.encoder.layer.10.attention.self.key.weight': 0.5, 'bert.encoder.layer.10.attention.self.key.bias': 0.0, 'bert.encoder.layer.10.attention.self.value.weight': 0.5, 'bert.encoder.layer.10.attention.self.value.bias': 0.0, 'bert.encoder.layer.10.attention.output.dense.weight': 0.5, 'bert.encoder.layer.10.attention.output.dense.bias': 0.0, 'bert.encoder.layer.10.intermediate.dense.weight': 0.5, 'bert.encoder.layer.10.intermediate.dense.bias': 0.0, 'bert.encoder.layer.10.output.dense.weight': 0.5, 'bert.encoder.layer.10.output.dense.bias': 0.0, 'bert.encoder.layer.11.attention.self.query.weight': 0.5, 'bert.encoder.layer.11.attention.self.query.bias': 0.0, 'bert.encoder.layer.11.attention.self.key.weight': 0.5, 'bert.encoder.layer.11.attention.self.key.bias': 0.0, 'bert.encoder.layer.11.attention.self.value.weight': 0.5, 'bert.encoder.layer.11.attention.self.value.bias': 0.0, 'bert.encoder.layer.11.attention.output.dense.weight': 0.5, 'bert.encoder.layer.11.attention.output.dense.bias': 0.0, 'bert.encoder.layer.11.intermediate.dense.weight': 0.5, 'bert.encoder.layer.11.intermediate.dense.bias': 0.0, 'bert.encoder.layer.11.output.dense.weight': 0.5, 'bert.encoder.layer.11.output.dense.bias': 0.0, 'bert.pooler.dense.weight': 0.09999932183159722, 'bert.pooler.dense.bias': 0.0, 'classifier.weight': 0.09993489583333333, 'classifier.bias': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 200/200 [04:30<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7504\n",
      "Precision: 0.6866, Recall: 0.4419, F1-Score: 0.4567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.35       797\n",
      "           1       0.82      0.10      0.19       775\n",
      "           2       0.87      0.48      0.62       795\n",
      "           3       0.91      0.47      0.62      1110\n",
      "           4       0.28      0.87      0.42      1260\n",
      "           5       0.92      0.12      0.21       882\n",
      "           6       0.89      0.20      0.33       940\n",
      "           7       0.15      0.50      0.23       473\n",
      "           8       0.52      0.54      0.53       746\n",
      "           9       0.29      0.73      0.42       689\n",
      "          10       0.66      0.49      0.57       670\n",
      "          11       0.74      0.26      0.38       312\n",
      "          12       0.54      0.51      0.53       665\n",
      "          13       0.89      0.32      0.47       314\n",
      "          14       0.84      0.40      0.55       756\n",
      "          15       0.99      0.82      0.90      1607\n",
      "\n",
      "    accuracy                           0.48     12791\n",
      "   macro avg       0.69      0.44      0.46     12791\n",
      "weighted avg       0.71      0.48      0.49     12791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "model, tokenizer, checkpoint = load_model(model_config)\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = load_data(name, batch_size=64)\n",
    "\n",
    "color_print(\"Start Time:\" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "color_print(\"#Module \" + str(i) + \" in progress....\")\n",
    "num_samples = 64\n",
    "\n",
    "positive_samples = sampling_class(\n",
    "    train_dataloader, i, num_samples, num_labels, True, 4, device=device\n",
    ")\n",
    "negative_samples = sampling_class(\n",
    "    train_dataloader, i, num_samples, num_labels, False, 4, device=device\n",
    ")\n",
    "\n",
    "all_samples = sampling_class(\n",
    "    train_dataloader, 200, 20, num_labels, False, 4, device=device\n",
    ")\n",
    "\n",
    "print(\"origin\")\n",
    "# evaluate_model(model, model_config, test_dataloader)\n",
    "\n",
    "module = copy.deepcopy(model)\n",
    "wr = WeightRemoverBert(model, p=0.9)\n",
    "ci = ConcernIdentificationBert(model, p=0.4)\n",
    "ti = TanglingIdentification(model, p=0.5)\n",
    "\n",
    "print(\"Start Magnitude pruning\")\n",
    "prune_magnitude(module, sparsity_ratio=0.1)\n",
    "print(get_sparsity(module)[0])\n",
    "print(\"Start Positive CI after sparse\")\n",
    "\n",
    "prune_concern_identification(\n",
    "    model,\n",
    "    module,\n",
    "    positive_samples,\n",
    "    include_layers=[\"attention\", \"intermediate\", \"output\"],\n",
    "    sparsity_ratio=0.5,\n",
    "    p=1,\n",
    ")\n",
    "\n",
    "print(get_sparsity(module))\n",
    "result = evaluate_model(module, model_config, test_dataloader)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
