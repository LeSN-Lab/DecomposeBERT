{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f3459d-aaad-4b51-b4c8-4ec84ed5fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc98c034-af69-4d41-b117-40c6db3b491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utils.helper import ModelConfig, color_print\n",
    "from utils.dataset_utils.load_dataset import (\n",
    "    load_data,\n",
    "    convert_dataset_labels_to_binary,\n",
    ")\n",
    "from utils.model_utils.load_model import load_model\n",
    "from utils.model_utils.evaluate import evaluate_model, get_sparsity\n",
    "from utils.model_utils.save_module import save_module\n",
    "from utils.decompose_utils.weight_remover import WeightRemoverBert\n",
    "from utils.decompose_utils.concern_identification import ConcernIdentificationBert\n",
    "from utils.decompose_utils.tangling_identification import TanglingIdentification\n",
    "from utils.decompose_utils.concern_modularization import ConcernModularizationBert\n",
    "from utils.decompose_utils.sampling import sampling_class\n",
    "from utils.prune_utils.prune import prune_magnitude, find_layers, LayerWrapper, prune_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6093a85-4bc7-47d0-b2bb-0cafbfba0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"OSDG\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = None\n",
    "model_config = ModelConfig(name, device)\n",
    "num_labels = model_config.config[\"num_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3d09b9-956a-4a6e-8e12-6656b2ed50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_concern_identification(\n",
    "    model,\n",
    "    module,\n",
    "    dataloader,\n",
    "    sparsity_ratio=0.4,\n",
    "    step_size=4,\n",
    "    p=1,\n",
    "    include_layers=None,\n",
    "    exclude_layers=None,\n",
    "):\n",
    "    ref_layers = find_layers(\n",
    "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    target_layers = find_layers(\n",
    "        module, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    wrappers = {}\n",
    "    ref_handle_list = []\n",
    "    target_handle_list = []\n",
    "\n",
    "    def get_hook(wrapper):\n",
    "        def hook(module, input, output):\n",
    "            wrapper.update(input, output)\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for (ref_name, ref_layer), (target_name, target_layer) in zip(\n",
    "        ref_layers.items(), target_layers.items()\n",
    "    ):\n",
    "        ref_wrapper = LayerWrapper(ref_name, ref_layer)\n",
    "        target_wrapper = LayerWrapper(target_name, target_layer)\n",
    "\n",
    "        wrappers[ref_name] = {\"ref\": ref_wrapper, \"target\": target_wrapper}\n",
    "\n",
    "        ref_handle = ref_layer.register_forward_hook(get_hook(ref_wrapper))\n",
    "        target_handle = target_layer.register_forward_hook(get_hook(target_wrapper))\n",
    "\n",
    "        ref_handle_list.append(ref_handle)\n",
    "        target_handle_list.append(target_handle)\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids, attn_mask, _, _ = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_ids, attention_mask=attn_mask)\n",
    "            module(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "    for handle in ref_handle_list + target_handle_list:\n",
    "        handle.remove()\n",
    "\n",
    "    for name, wrapper_pair in wrappers.items():\n",
    "        wrapper_pair[\"ref\"].update_batch()\n",
    "        wrapper_pair[\"target\"].update_batch()\n",
    "\n",
    "        ref_outputs = wrapper_pair[\"ref\"].outputs\n",
    "        target_outputs = wrapper_pair[\"target\"].outputs\n",
    "\n",
    "        current_weight = wrapper_pair[\"target\"].layer.weight.data\n",
    "\n",
    "        output_loss = (\n",
    "            target_outputs - ref_outputs\n",
    "        )  # (batch_size, seq_dim, output_dim)\n",
    "\n",
    "        output_loss = output_loss.reshape((-1, output_loss.shape[-1]))  # (batch_size * seq_dim, output_dim)\n",
    "\n",
    "        output_loss = output_loss.t().to(device) # (output_dim, batch_size * seq_dim)\n",
    "        importance_score = torch.norm(output_loss, p=2, dim=1) ** 2 # (output_dim)\n",
    "\n",
    "        importance_score = torch.abs(current_weight) * importance_score.reshape((-1, 1)) # (output_dim, input_dim) * (output_dim, 1) = (output_dim, input_dim)\n",
    "\n",
    "        W_mask = torch.zeros_like(importance_score) == 1\n",
    "        sort_res = torch.sort(importance_score, dim=0, stable=True)\n",
    "        indices = sort_res[1][:int(importance_score.shape[0] * sparsity_ratio), :]\n",
    "        W_mask.scatter_(0, indices, True)\n",
    "        current_weight[W_mask] = 0\n",
    "\n",
    "        wrapper_pair[\"ref\"].remove()\n",
    "        wrapper_pair[\"target\"].remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0ac679-8132-4a34-a818-940ed3c19a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'model_name': 'sadickam/sdg-classification-bert', 'task_type': 'classification', 'architectures': 'bert', 'dataset_name': 'OSDG', 'num_labels': 16, 'cache_dir': 'Models'}\n",
      "The model sadickam/sdg-classification-bert is loaded.\n",
      "{'dataset_name': 'OSDG', 'path': 'albertmartinez/OSDG', 'config_name': '2024-01-01', 'text_column': 'text', 'label_column': 'labels', 'cache_dir': 'Datasets/OSDG', 'task_type': 'classification'}\n",
      "Loading cached dataset OSDG.\n",
      "The dataset OSDG is loaded\n",
      "Start Time:13:23:28\n",
      "#Module 0 in progress....\n",
      "origin\n",
      "Start Magnitude pruning\n",
      "0.09919858441371328\n",
      "Start Positive CI after sparse\n",
      "(0.5944862664659172, {'bert.encoder.layer.0.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.0.attention.self.query.bias': 0.0, 'bert.encoder.layer.0.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.0.attention.self.key.bias': 0.0, 'bert.encoder.layer.0.attention.self.value.weight': 0.5989634195963541, 'bert.encoder.layer.0.attention.self.value.bias': 0.0, 'bert.encoder.layer.0.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.0.attention.output.dense.bias': 0.0, 'bert.encoder.layer.0.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.0.intermediate.dense.bias': 0.0, 'bert.encoder.layer.0.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.0.output.dense.bias': 0.0, 'bert.encoder.layer.1.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.self.query.bias': 0.0, 'bert.encoder.layer.1.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.self.key.bias': 0.0, 'bert.encoder.layer.1.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.self.value.bias': 0.0, 'bert.encoder.layer.1.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.output.dense.bias': 0.0, 'bert.encoder.layer.1.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.1.intermediate.dense.bias': 0.0, 'bert.encoder.layer.1.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.1.output.dense.bias': 0.0, 'bert.encoder.layer.2.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.self.query.bias': 0.0, 'bert.encoder.layer.2.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.self.key.bias': 0.0, 'bert.encoder.layer.2.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.self.value.bias': 0.0, 'bert.encoder.layer.2.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.output.dense.bias': 0.0, 'bert.encoder.layer.2.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.2.intermediate.dense.bias': 0.0, 'bert.encoder.layer.2.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.2.output.dense.bias': 0.0, 'bert.encoder.layer.3.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.self.query.bias': 0.0, 'bert.encoder.layer.3.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.self.key.bias': 0.0, 'bert.encoder.layer.3.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.self.value.bias': 0.0, 'bert.encoder.layer.3.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.output.dense.bias': 0.0, 'bert.encoder.layer.3.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.3.intermediate.dense.bias': 0.0, 'bert.encoder.layer.3.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.3.output.dense.bias': 0.0, 'bert.encoder.layer.4.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.4.attention.self.query.bias': 0.0, 'bert.encoder.layer.4.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.4.attention.self.key.bias': 0.0, 'bert.encoder.layer.4.attention.self.value.weight': 0.5990922715928819, 'bert.encoder.layer.4.attention.self.value.bias': 0.0, 'bert.encoder.layer.4.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.4.attention.output.dense.bias': 0.0, 'bert.encoder.layer.4.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.4.intermediate.dense.bias': 0.0, 'bert.encoder.layer.4.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.4.output.dense.bias': 0.0, 'bert.encoder.layer.5.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.5.attention.self.query.bias': 0.0, 'bert.encoder.layer.5.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.5.attention.self.key.bias': 0.0, 'bert.encoder.layer.5.attention.self.value.weight': 0.5991024441189237, 'bert.encoder.layer.5.attention.self.value.bias': 0.0, 'bert.encoder.layer.5.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.5.attention.output.dense.bias': 0.0, 'bert.encoder.layer.5.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.5.intermediate.dense.bias': 0.0, 'bert.encoder.layer.5.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.5.output.dense.bias': 0.0, 'bert.encoder.layer.6.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.6.attention.self.query.bias': 0.0, 'bert.encoder.layer.6.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.6.attention.self.key.bias': 0.0, 'bert.encoder.layer.6.attention.self.value.weight': 0.5990261501736112, 'bert.encoder.layer.6.attention.self.value.bias': 0.0, 'bert.encoder.layer.6.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.6.attention.output.dense.bias': 0.0, 'bert.encoder.layer.6.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.6.intermediate.dense.bias': 0.0, 'bert.encoder.layer.6.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.6.output.dense.bias': 0.0, 'bert.encoder.layer.7.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.7.attention.self.query.bias': 0.0, 'bert.encoder.layer.7.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.7.attention.self.key.bias': 0.0, 'bert.encoder.layer.7.attention.self.value.weight': 0.5989651150173612, 'bert.encoder.layer.7.attention.self.value.bias': 0.0, 'bert.encoder.layer.7.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.7.attention.output.dense.bias': 0.0, 'bert.encoder.layer.7.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.7.intermediate.dense.bias': 0.0, 'bert.encoder.layer.7.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.7.output.dense.bias': 0.0, 'bert.encoder.layer.8.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.8.attention.self.query.bias': 0.0, 'bert.encoder.layer.8.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.8.attention.self.key.bias': 0.0, 'bert.encoder.layer.8.attention.self.value.weight': 0.5989922417534722, 'bert.encoder.layer.8.attention.self.value.bias': 0.0, 'bert.encoder.layer.8.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.8.attention.output.dense.bias': 0.0, 'bert.encoder.layer.8.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.8.intermediate.dense.bias': 0.0, 'bert.encoder.layer.8.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.8.output.dense.bias': 0.0, 'bert.encoder.layer.9.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.self.query.bias': 0.0, 'bert.encoder.layer.9.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.self.key.bias': 0.0, 'bert.encoder.layer.9.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.self.value.bias': 0.0, 'bert.encoder.layer.9.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.output.dense.bias': 0.0, 'bert.encoder.layer.9.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.9.intermediate.dense.bias': 0.0, 'bert.encoder.layer.9.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.9.output.dense.bias': 0.0, 'bert.encoder.layer.10.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.10.attention.self.query.bias': 0.0, 'bert.encoder.layer.10.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.10.attention.self.key.bias': 0.0, 'bert.encoder.layer.10.attention.self.value.weight': 0.598968505859375, 'bert.encoder.layer.10.attention.self.value.bias': 0.0, 'bert.encoder.layer.10.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.10.attention.output.dense.bias': 0.0, 'bert.encoder.layer.10.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.10.intermediate.dense.bias': 0.0, 'bert.encoder.layer.10.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.10.output.dense.bias': 0.0, 'bert.encoder.layer.11.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.11.attention.self.query.bias': 0.0, 'bert.encoder.layer.11.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.11.attention.self.key.bias': 0.0, 'bert.encoder.layer.11.attention.self.value.weight': 0.5989651150173612, 'bert.encoder.layer.11.attention.self.value.bias': 0.0, 'bert.encoder.layer.11.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.11.attention.output.dense.bias': 0.0, 'bert.encoder.layer.11.intermediate.dense.weight': 0.5999348958333334, 'bert.encoder.layer.11.intermediate.dense.bias': 0.0, 'bert.encoder.layer.11.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.11.output.dense.bias': 0.0, 'bert.pooler.dense.weight': 0.0, 'bert.pooler.dense.bias': 0.0, 'classifier.weight': 0.0, 'classifier.bias': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 200/200 [02:24<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1752\n",
      "Precision: 0.6840, Recall: 0.6382, F1-Score: 0.6415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56       797\n",
      "           1       0.83      0.41      0.55       775\n",
      "           2       0.79      0.81      0.80       795\n",
      "           3       0.88      0.69      0.77      1110\n",
      "           4       0.61      0.83      0.70      1260\n",
      "           5       0.87      0.57      0.69       882\n",
      "           6       0.84      0.59      0.69       940\n",
      "           7       0.32      0.47      0.38       473\n",
      "           8       0.53      0.77      0.62       746\n",
      "           9       0.46      0.55      0.50       689\n",
      "          10       0.59      0.70      0.64       670\n",
      "          11       0.49      0.54      0.51       312\n",
      "          12       0.44      0.75      0.55       665\n",
      "          13       0.88      0.51      0.65       314\n",
      "          14       0.84      0.64      0.72       756\n",
      "          15       0.97      0.88      0.93      1607\n",
      "\n",
      "    accuracy                           0.67     12791\n",
      "   macro avg       0.68      0.64      0.64     12791\n",
      "weighted avg       0.72      0.67      0.68     12791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "model, tokenizer, checkpoint = load_model(model_config)\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = load_data(name, batch_size=64)\n",
    "\n",
    "color_print(\"Start Time:\" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "color_print(\"#Module \" + str(i) + \" in progress....\")\n",
    "num_samples = 64\n",
    "\n",
    "positive_samples = sampling_class(\n",
    "    train_dataloader, i, num_samples, num_labels, True, 4, device=device\n",
    ")\n",
    "negative_samples = sampling_class(\n",
    "    train_dataloader, i, num_samples, num_labels, False, 4, device=device\n",
    ")\n",
    "\n",
    "all_samples = sampling_class(\n",
    "    train_dataloader, 200, 20, num_labels, False, 4, device=device\n",
    ")\n",
    "\n",
    "print(\"origin\")\n",
    "# evaluate_model(model, model_config, test_dataloader)\n",
    "\n",
    "module = copy.deepcopy(model)\n",
    "wr = WeightRemoverBert(model, p=0.9)\n",
    "ci = ConcernIdentificationBert(model, p=0.4)\n",
    "ti = TanglingIdentification(model, p=0.5)\n",
    "\n",
    "print(\"Start Magnitude pruning\")\n",
    "prune_magnitude(module, include_layers=[\"attention\", \"intermediate\", \"output\"], sparsity_ratio=0.1)\n",
    "print(get_sparsity(module)[0])\n",
    "print(\"Start Positive CI after sparse\")\n",
    "\n",
    "prune_concern_identification(\n",
    "    model,\n",
    "    module,\n",
    "    positive_samples,\n",
    "    include_layers=[\"attention\", \"intermediate\", \"output\"],\n",
    "    sparsity_ratio=0.6,\n",
    "    p=1,\n",
    ")\n",
    "\n",
    "print(get_sparsity(module))\n",
    "result = evaluate_model(module, model_config, test_dataloader)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22627a04-ed1a-4a0a-adc4-5dffddaac1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0054\n",
      "Precision: 0.7293, Recall: 0.7089, F1-Score: 0.7091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       797\n",
      "           1       0.85      0.51      0.63       775\n",
      "           2       0.86      0.83      0.84       795\n",
      "           3       0.87      0.74      0.80      1110\n",
      "           4       0.68      0.85      0.75      1260\n",
      "           5       0.89      0.65      0.75       882\n",
      "           6       0.85      0.65      0.74       940\n",
      "           7       0.44      0.47      0.45       473\n",
      "           8       0.54      0.82      0.65       746\n",
      "           9       0.47      0.71      0.56       689\n",
      "          10       0.71      0.74      0.72       670\n",
      "          11       0.63      0.64      0.64       312\n",
      "          12       0.60      0.74      0.67       665\n",
      "          13       0.81      0.79      0.80       314\n",
      "          14       0.84      0.73      0.78       756\n",
      "          15       0.96      0.91      0.93      1607\n",
      "\n",
      "    accuracy                           0.73     12791\n",
      "   macro avg       0.73      0.71      0.71     12791\n",
      "weighted avg       0.76      0.73      0.74     12791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(negative_samples):\n",
    "    input_ids, attn_mask, _, total_sampled = batch\n",
    "    with torch.no_grad():\n",
    "        ti.propagate(module, input_ids)\n",
    "    # if idx % eval_step:\n",
    "    #     evaluate_model(module, model_config, test_dataloader)\n",
    "result = evaluate_model(module, model_config, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471d9e04-b2fb-4b4b-b9c2-09f6b84adda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5096870847372806, {'bert.encoder.layer.0.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.0.attention.self.query.bias': 0.0, 'bert.encoder.layer.0.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.0.attention.self.key.bias': 0.0, 'bert.encoder.layer.0.attention.self.value.weight': 0.5989634195963541, 'bert.encoder.layer.0.attention.self.value.bias': 0.0, 'bert.encoder.layer.0.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.0.attention.output.dense.bias': 0.0, 'bert.encoder.layer.0.intermediate.dense.weight': 0.46533838907877606, 'bert.encoder.layer.0.intermediate.dense.bias': 0.0, 'bert.encoder.layer.0.output.dense.weight': 0.4637468126085069, 'bert.encoder.layer.0.output.dense.bias': 0.0, 'bert.encoder.layer.1.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.self.query.bias': 0.0, 'bert.encoder.layer.1.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.self.key.bias': 0.0, 'bert.encoder.layer.1.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.self.value.bias': 0.0, 'bert.encoder.layer.1.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.1.attention.output.dense.bias': 0.0, 'bert.encoder.layer.1.intermediate.dense.weight': 0.4642473856608073, 'bert.encoder.layer.1.intermediate.dense.bias': 0.0, 'bert.encoder.layer.1.output.dense.weight': 0.4649658203125, 'bert.encoder.layer.1.output.dense.bias': 0.0, 'bert.encoder.layer.2.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.self.query.bias': 0.0, 'bert.encoder.layer.2.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.self.key.bias': 0.0, 'bert.encoder.layer.2.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.self.value.bias': 0.0, 'bert.encoder.layer.2.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.2.attention.output.dense.bias': 0.0, 'bert.encoder.layer.2.intermediate.dense.weight': 0.4688279893663194, 'bert.encoder.layer.2.intermediate.dense.bias': 0.0, 'bert.encoder.layer.2.output.dense.weight': 0.4660174051920573, 'bert.encoder.layer.2.output.dense.bias': 0.0, 'bert.encoder.layer.3.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.self.query.bias': 0.0, 'bert.encoder.layer.3.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.self.key.bias': 0.0, 'bert.encoder.layer.3.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.self.value.bias': 0.0, 'bert.encoder.layer.3.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.3.attention.output.dense.bias': 0.0, 'bert.encoder.layer.3.intermediate.dense.weight': 0.4702805413140191, 'bert.encoder.layer.3.intermediate.dense.bias': 0.0, 'bert.encoder.layer.3.output.dense.weight': 0.46716393364800346, 'bert.encoder.layer.3.output.dense.bias': 0.0, 'bert.encoder.layer.4.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.4.attention.self.query.bias': 0.0, 'bert.encoder.layer.4.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.4.attention.self.key.bias': 0.0, 'bert.encoder.layer.4.attention.self.value.weight': 0.5990922715928819, 'bert.encoder.layer.4.attention.self.value.bias': 0.0, 'bert.encoder.layer.4.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.4.attention.output.dense.bias': 0.0, 'bert.encoder.layer.4.intermediate.dense.weight': 0.47115198771158856, 'bert.encoder.layer.4.intermediate.dense.bias': 0.0, 'bert.encoder.layer.4.output.dense.weight': 0.4662708706325955, 'bert.encoder.layer.4.output.dense.bias': 0.0, 'bert.encoder.layer.5.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.5.attention.self.query.bias': 0.0, 'bert.encoder.layer.5.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.5.attention.self.key.bias': 0.0, 'bert.encoder.layer.5.attention.self.value.weight': 0.5991024441189237, 'bert.encoder.layer.5.attention.self.value.bias': 0.0, 'bert.encoder.layer.5.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.5.attention.output.dense.bias': 0.0, 'bert.encoder.layer.5.intermediate.dense.weight': 0.47183863321940106, 'bert.encoder.layer.5.intermediate.dense.bias': 0.0, 'bert.encoder.layer.5.output.dense.weight': 0.4680154588487413, 'bert.encoder.layer.5.output.dense.bias': 0.0, 'bert.encoder.layer.6.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.6.attention.self.query.bias': 0.0, 'bert.encoder.layer.6.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.6.attention.self.key.bias': 0.0, 'bert.encoder.layer.6.attention.self.value.weight': 0.5990261501736112, 'bert.encoder.layer.6.attention.self.value.bias': 0.0, 'bert.encoder.layer.6.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.6.attention.output.dense.bias': 0.0, 'bert.encoder.layer.6.intermediate.dense.weight': 0.4742079840766059, 'bert.encoder.layer.6.intermediate.dense.bias': 0.0, 'bert.encoder.layer.6.output.dense.weight': 0.46870168050130206, 'bert.encoder.layer.6.output.dense.bias': 0.0, 'bert.encoder.layer.7.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.7.attention.self.query.bias': 0.0, 'bert.encoder.layer.7.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.7.attention.self.key.bias': 0.0, 'bert.encoder.layer.7.attention.self.value.weight': 0.5989651150173612, 'bert.encoder.layer.7.attention.self.value.bias': 0.0, 'bert.encoder.layer.7.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.7.attention.output.dense.bias': 0.0, 'bert.encoder.layer.7.intermediate.dense.weight': 0.4760729471842448, 'bert.encoder.layer.7.intermediate.dense.bias': 0.0, 'bert.encoder.layer.7.output.dense.weight': 0.4712045457628038, 'bert.encoder.layer.7.output.dense.bias': 0.0, 'bert.encoder.layer.8.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.8.attention.self.query.bias': 0.0, 'bert.encoder.layer.8.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.8.attention.self.key.bias': 0.0, 'bert.encoder.layer.8.attention.self.value.weight': 0.5989922417534722, 'bert.encoder.layer.8.attention.self.value.bias': 0.0, 'bert.encoder.layer.8.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.8.attention.output.dense.bias': 0.0, 'bert.encoder.layer.8.intermediate.dense.weight': 0.47844823201497394, 'bert.encoder.layer.8.intermediate.dense.bias': 0.0, 'bert.encoder.layer.8.output.dense.weight': 0.47399944729275173, 'bert.encoder.layer.8.output.dense.bias': 0.0, 'bert.encoder.layer.9.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.self.query.bias': 0.0, 'bert.encoder.layer.9.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.self.key.bias': 0.0, 'bert.encoder.layer.9.attention.self.value.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.self.value.bias': 0.0, 'bert.encoder.layer.9.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.9.attention.output.dense.bias': 0.0, 'bert.encoder.layer.9.intermediate.dense.weight': 0.4774971008300781, 'bert.encoder.layer.9.intermediate.dense.bias': 0.0, 'bert.encoder.layer.9.output.dense.weight': 0.4764578077528212, 'bert.encoder.layer.9.output.dense.bias': 0.0, 'bert.encoder.layer.10.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.10.attention.self.query.bias': 0.0, 'bert.encoder.layer.10.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.10.attention.self.key.bias': 0.0, 'bert.encoder.layer.10.attention.self.value.weight': 0.598968505859375, 'bert.encoder.layer.10.attention.self.value.bias': 0.0, 'bert.encoder.layer.10.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.10.attention.output.dense.bias': 0.0, 'bert.encoder.layer.10.intermediate.dense.weight': 0.4782986111111111, 'bert.encoder.layer.10.intermediate.dense.bias': 0.0, 'bert.encoder.layer.10.output.dense.weight': 0.4730356004503038, 'bert.encoder.layer.10.output.dense.bias': 0.0, 'bert.encoder.layer.11.attention.self.query.weight': 0.5989583333333334, 'bert.encoder.layer.11.attention.self.query.bias': 0.0, 'bert.encoder.layer.11.attention.self.key.weight': 0.5989583333333334, 'bert.encoder.layer.11.attention.self.key.bias': 0.0, 'bert.encoder.layer.11.attention.self.value.weight': 0.5989651150173612, 'bert.encoder.layer.11.attention.self.value.bias': 0.0, 'bert.encoder.layer.11.attention.output.dense.weight': 0.5989583333333334, 'bert.encoder.layer.11.attention.output.dense.bias': 0.0, 'bert.encoder.layer.11.intermediate.dense.weight': 0.4787529839409722, 'bert.encoder.layer.11.intermediate.dense.bias': 0.0, 'bert.encoder.layer.11.output.dense.weight': 0.4747551812065972, 'bert.encoder.layer.11.output.dense.bias': 0.0, 'bert.pooler.dense.weight': 0.0, 'bert.pooler.dense.bias': 0.0, 'classifier.weight': 0.0, 'classifier.bias': 0.0})\n"
     ]
    }
   ],
   "source": [
    "print(get_sparsity(module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50b449c-3398-4138-b6d2-a56570c0d0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09919858441371328\n",
      "Start Positive CI after sparse\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(get_sparsity(module)[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStart Positive CI after sparse\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mprune_ci\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpositive_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mattention\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mintermediate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43msparsity_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.6\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(get_sparsity(module))\n\u001B[1;32m     16\u001B[0m result \u001B[38;5;241m=\u001B[39m evaluate_model(module, model_config, test_dataloader)\n",
      "File \u001B[0;32m~/LESN/Decompose/DecomposeTransformer/utils/prune_utils/prune.py:274\u001B[0m, in \u001B[0;36mprune_ci\u001B[0;34m(model, module, dataloader, sparsity_ratio, step_size, p, include_layers, exclude_layers)\u001B[0m\n\u001B[1;32m    271\u001B[0m     handle\u001B[38;5;241m.\u001B[39mremove()\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, wrapper_pair \u001B[38;5;129;01min\u001B[39;00m wrappers\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 274\u001B[0m     \u001B[43mwrapper_pair\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mref\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m     wrapper_pair[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mupdate_batch()\n\u001B[1;32m    276\u001B[0m     current_weight \u001B[38;5;241m=\u001B[39m wrapper_pair[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mlayer\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/LESN/Decompose/DecomposeTransformer/utils/prune_utils/prune.py:29\u001B[0m, in \u001B[0;36mLayerWrapper.update_batch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "module = copy.deepcopy(model)\n",
    "prune_magnitude(module, include_layers=[\"attention\", \"intermediate\", \"output\"], sparsity_ratio=0.1)\n",
    "print(get_sparsity(module)[0])\n",
    "print(\"Start Positive CI after sparse\")\n",
    "\n",
    "prune_ci(\n",
    "    model,\n",
    "    module,\n",
    "    positive_samples,\n",
    "    include_layers=[\"attention\", \"intermediate\", \"output\"],\n",
    "    sparsity_ratio=0.6,\n",
    "    p=1,\n",
    ")\n",
    "\n",
    "print(get_sparsity(module))\n",
    "result = evaluate_model(module, model_config, test_dataloader)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872dbaaf-661b-403d-a6dd-17c0a801de26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
