{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6521b371-7c72-40e4-b5ae-83a6ee1c54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e662df3-6d15-4d89-8c23-82ee3e37822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 13 21:14:19 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:27:00.0 Off |                  Off |\n",
      "| 54%   74C    P2             100W / 200W |  27059MiB / 49140MiB |      7%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:38:00.0 Off |                  Off |\n",
      "| 73%   85C    P0             118W / 200W |      6MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2165509      C   python                                    26260MiB |\n",
      "|    0   N/A  N/A   2340693      C   /home/deeparc/anaconda3/bin/python          786MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9021fc-d9c3-4825-a91e-ceb46717ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "sys.path.append(os.path.dirname(pwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8fa367-7678-46fb-b95a-252b525a9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils.evaluate import evaluate_model\n",
    "from utils.model_utils.load_model import *\n",
    "from utils.model_utils.model_config import ModelConfig\n",
    "from utils.dataset_utils.load_dataset import load_data\n",
    "from utils.decompose_utils.weight_remover import WeightRemoverBert\n",
    "from utils.decompose_utils.concern_identification import ConcernIdentificationBert\n",
    "from utils.decompose_utils.tangling_identification import TanglingIdentification\n",
    "from transformers import AutoConfig\n",
    "from utils.model_utils.save_module import save_module\n",
    "from datetime import datetime\n",
    "from utils.decompose_utils.sampling import sampling_class\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ec363d-0193-4a38-9b36-e609668ddbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sadickam/sdg-classification-bert\"\n",
    "model_type = \"pretrained\"\n",
    "data = \"OSDG\"\n",
    "num_labels = 16\n",
    "\n",
    "\n",
    "# model_name = \"textattack/bert-base-uncased-imdb\"\n",
    "# model_type = \"pretrained\"\n",
    "# data = \"IMDb\"\n",
    "# num_labels = 2\n",
    "\n",
    "# model_name = \"fabriceyhc/bert-base-uncased-yahoo_answers_topics\"\n",
    "# model_type = \"pretrained\"\n",
    "# data = \"Yahoo\"\n",
    "# num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4553a7e1-06ec-4323-9843-00660ef0fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d0ff54-1c9d-4ec0-86b7-eea274c61b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/Minwoo/LESN/Decompose/DecomposeBERT/Models/Configs/pretrained/sadickam/sdg-classification-bert exists.\n",
      "Loading the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Minwoo/.conda/envs/DecomposeBERT/lib/python3.8/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/Minwoo/.conda/envs/DecomposeBERT/lib/python3.8/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time:21:14:51\n"
     ]
    }
   ],
   "source": [
    "checkpoint_name = None\n",
    "config = AutoConfig.from_pretrained(model_name, num_labels=num_labels)\n",
    "model_config = ModelConfig(\n",
    "    _model_name=model_name,\n",
    "    _model_type=model_type,\n",
    "    _data=data,\n",
    "    _transformer_config=config,\n",
    "    _checkpoint_name=checkpoint_name,\n",
    "    _device=device,\n",
    ")\n",
    "model, tokenizer, checkpoint = load_classification_model(model_config, train_mode=False)\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    model_config, batch_size=32, test_size=0.3\n",
    ")\n",
    "print(\"Start Time:\" + datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1711493-8f25-4305-b4f7-e59673d56956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Module 15 in progress....\n",
      "origin\n",
      "0\n",
      "Start Positive CI sparse\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Start Positive CI after sparse\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Start Negative TI\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "i = 15\n",
    "print(\"#Module \" + str(i) + \" in progress....\")\n",
    "num_samples = 64\n",
    "\n",
    "positive_samples = sampling_class(\n",
    "    train_dataloader, i, num_samples, num_labels, True, 4, device=device\n",
    ")\n",
    "negative_samples = sampling_class(\n",
    "    train_dataloader, i, num_samples, num_labels, False, 4, device=device\n",
    ")\n",
    "\n",
    "all_samples = sampling_class(\n",
    "    train_dataloader, 200, 20, num_labels, False, 4, device=device\n",
    ")\n",
    "\n",
    "module1 = copy.deepcopy(model)\n",
    "w = WeightRemoverBert(model, p=0.9)\n",
    "ci1 = ConcernIdentificationBert(model, p=0.4)\n",
    "ti1 = TanglingIdentification(model, p=0.5)\n",
    "\n",
    "ff1 = [\n",
    "    [torch.sum(model.bert.encoder.layer[num].intermediate.dense.weight != 0).item()]\n",
    "    for num in range(config.num_hidden_layers)\n",
    "]\n",
    "ff2 = [\n",
    "    [torch.sum(model.bert.encoder.layer[num].output.dense.weight != 0).item()]\n",
    "    for num in range(config.num_hidden_layers)\n",
    "]\n",
    "pooler = [torch.sum(model.bert.pooler.dense.weight != 0).item()]\n",
    "classifier = [torch.sum(model.classifier.weight != 0).item()]\n",
    "print(\"origin\")\n",
    "j = 0\n",
    "print(j)\n",
    "# result = evaluate_model(model, model_config, test_dataloader)\n",
    "\n",
    "print(\"Start Positive CI sparse\")\n",
    "\n",
    "for batch in all_samples:\n",
    "    input_ids, attn_mask, _, total_sampled = batch\n",
    "    with torch.no_grad():\n",
    "        t1 = w.propagate(module1, input_ids)\n",
    "    for num in range(config.num_hidden_layers):\n",
    "        ff1[num].append(\n",
    "            torch.sum(\n",
    "                module1.bert.encoder.layer[num].intermediate.dense.weight != 0\n",
    "            ).item()\n",
    "        )\n",
    "        ff2[num].append(\n",
    "            torch.sum(\n",
    "                module1.bert.encoder.layer[num].output.dense.weight != 0\n",
    "            ).item()\n",
    "        )\n",
    "    pooler.append(torch.sum(module1.bert.pooler.dense.weight != 0).item())\n",
    "    classifier.append(torch.sum(module1.classifier.weight != 0).item())\n",
    "\n",
    "    j += 1\n",
    "    print(j)\n",
    "\n",
    "    # result = evaluate_model(module1, model_config, test_dataloader)\n",
    "\n",
    "print(\"Start Positive CI after sparse\")\n",
    "\n",
    "for batch in positive_samples:\n",
    "    input_ids, attn_mask, _, total_sampled = batch\n",
    "    with torch.no_grad():\n",
    "        t1 = ci1.propagate(module1, input_ids)\n",
    "    for num in range(config.num_hidden_layers):\n",
    "        ff1[num].append(\n",
    "            torch.sum(\n",
    "                module1.bert.encoder.layer[num].intermediate.dense.weight != 0\n",
    "            ).item()\n",
    "        )\n",
    "        ff2[num].append(\n",
    "            torch.sum(\n",
    "                module1.bert.encoder.layer[num].output.dense.weight != 0\n",
    "            ).item()\n",
    "        )\n",
    "    pooler.append(torch.sum(module1.bert.pooler.dense.weight != 0).item())\n",
    "    classifier.append(torch.sum(module1.classifier.weight != 0).item())\n",
    "\n",
    "    j += 1\n",
    "    print(j)\n",
    "\n",
    "    # result = evaluate_model(module1, model_config, test_dataloader)\n",
    "\n",
    "print(\"Start Negative TI\")\n",
    "\n",
    "for batch in negative_samples:\n",
    "    input_ids, attn_mask, _, total_sampled = batch\n",
    "    with torch.no_grad():\n",
    "        t = ti1.propagate(module1, input_ids)\n",
    "    for num in range(config.num_hidden_layers):\n",
    "        ff1[num].append(\n",
    "            torch.sum(\n",
    "                module1.bert.encoder.layer[num].intermediate.dense.weight != 0\n",
    "            ).item()\n",
    "        )\n",
    "        ff2[num].append(\n",
    "            torch.sum(\n",
    "                module1.bert.encoder.layer[num].output.dense.weight != 0\n",
    "            ).item()\n",
    "        )\n",
    "    pooler.append(torch.sum(module1.bert.pooler.dense.weight != 0).item())\n",
    "    classifier.append(torch.sum(module1.classifier.weight != 0).item())\n",
    "\n",
    "    j += 1\n",
    "    print(j)\n",
    "\n",
    "    # result = evaluate_model(module1, model_config, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c360f-9598-4dc2-afed-b377eab102d4",
   "metadata": {},
   "source": [
    "result = evaluate_model(model, model_config, test_dataloader)\n",
    "Loss: 0.9480\n",
    "Precision: 0.7801, Recall: 0.7867, F1-Score: 0.7793\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.66      0.71       797\n",
    "           1       0.84      0.72      0.78       775\n",
    "           2       0.88      0.87      0.88       795\n",
    "           3       0.87      0.83      0.85      1110\n",
    "           4       0.86      0.80      0.83      1260\n",
    "           5       0.88      0.69      0.77       882\n",
    "           6       0.85      0.80      0.83       940\n",
    "           7       0.49      0.61      0.54       473\n",
    "           8       0.66      0.85      0.74       746\n",
    "           9       0.62      0.73      0.67       689\n",
    "          10       0.75      0.79      0.77       670\n",
    "          11       0.62      0.81      0.70       312\n",
    "          12       0.73      0.81      0.77       665\n",
    "          13       0.83      0.85      0.84       314\n",
    "          14       0.85      0.78      0.81       756\n",
    "          15       0.97      0.98      0.97      1607\n",
    "\n",
    "    accuracy                           0.80     12791\n",
    "   macro avg       0.78      0.79      0.78     12791\n",
    "weighted avg       0.81      0.80      0.80     12791"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089181b-6aa9-49ec-a242-ba1f27d1c616",
   "metadata": {},
   "source": [
    "result = evaluate_model(module1, model_config, test_dataloader)\n",
    "Loss: 0.8861\n",
    "Precision: 0.7749, Recall: 0.7805, F1-Score: 0.7729\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.65      0.70       797\n",
    "           1       0.86      0.69      0.76       775\n",
    "           2       0.86      0.88      0.87       795\n",
    "           3       0.88      0.81      0.84      1110\n",
    "           4       0.86      0.80      0.83      1260\n",
    "           5       0.89      0.68      0.77       882\n",
    "           6       0.85      0.81      0.83       940\n",
    "           7       0.48      0.59      0.53       473\n",
    "           8       0.66      0.85      0.74       746\n",
    "           9       0.57      0.74      0.64       689\n",
    "          10       0.78      0.76      0.77       670\n",
    "          11       0.61      0.81      0.70       312\n",
    "          12       0.71      0.81      0.76       665\n",
    "          13       0.83      0.85      0.84       314\n",
    "          14       0.85      0.78      0.81       756\n",
    "          15       0.98      0.97      0.97      1607\n",
    "\n",
    "    accuracy                           0.79     12791\n",
    "   macro avg       0.77      0.78      0.77     12791\n",
    "weighted avg       0.81      0.79      0.80     12791\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a0cbc3-ee79-4b44-8d74-34135d7beddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.decompose_utils.concern_modularization import ConcernModularizationBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efab8af2-39de-42bf-a9fe-0644caacc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqqq(module2, conv_collected_input_ids, conv_collected_attention_mask, conv_collected_labels, converted_test_dataloader):\n",
    "    logits = module2(conv_collected_input_ids, conv_collected_attention_mask).logits\n",
    "    result = evaluate_model(module2, model_config, converted_test_dataloader)\n",
    "    print(logits)\n",
    "    pred = logits.argmax(dim=1)\n",
    "    print(pred)\n",
    "    print(conv_collected_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ffbe55-8307-48c1-91fb-3bd3683256a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_input_ids = []\n",
    "collected_attention_mask = []\n",
    "collected_labels = []\n",
    "count = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    if count >= 100:\n",
    "        break\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(model_config.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model_config.device)\n",
    "    labels = batch[\"labels\"].to(model_config.device)\n",
    "\n",
    "    # Add data to lists\n",
    "    collected_input_ids.append(input_ids)\n",
    "    collected_attention_mask.append(attention_mask)\n",
    "    collected_labels.append(labels)\n",
    "\n",
    "    # Increment the count by the batch size\n",
    "    count += input_ids.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce141f9-6c73-40fe-a300-434cbe7f1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qqqq(model, collected_input_ids[1], collected_attention_mask[1], collected_labels[1], test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2931fc-4449-418d-aac2-72136f6c996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_utils.load_dataset import convert_dataset_labels_to_binary\n",
    "converted_train_dataloader = convert_dataset_labels_to_binary(train_dataloader, i)\n",
    "converted_valid_dataloader = convert_dataset_labels_to_binary(valid_dataloader, i)\n",
    "converted_test_dataloader = convert_dataset_labels_to_binary(test_dataloader, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de29721-d201-4810-b2d6-fd6071129231",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_collected_input_ids = []\n",
    "conv_collected_attention_mask = []\n",
    "conv_collected_labels = []\n",
    "count = 0\n",
    "\n",
    "for batch in converted_test_dataloader:\n",
    "    if count >= 100:\n",
    "        break\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(model_config.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model_config.device)\n",
    "    labels = batch[\"labels\"].to(model_config.device)\n",
    "\n",
    "    # Add data to lists\n",
    "    conv_collected_input_ids.append(input_ids)\n",
    "    conv_collected_attention_mask.append(attention_mask)\n",
    "    conv_collected_labels.append(labels)\n",
    "\n",
    "    # Increment the count by the batch size\n",
    "    count += input_ids.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a61c8b-ccf4-430b-ba3f-88967ee64215",
   "metadata": {},
   "source": [
    "# module -> binary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa1de08-2f3f-4716-9f4f-2234e13d49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pppp(module1, ci1, ti1, model_config):\n",
    "    ConcernModularizationBert.channeling(module1, ci1.active_node, ti1.active_node,0, model_config.device)\n",
    "    from transformers import BertForSequenceClassification\n",
    "    config1 = AutoConfig.from_pretrained(model_name)\n",
    "    config1.id2label = {0: \"negative\", 1: \"positive\"}\n",
    "    config1.label2id = {\"negative\": 0, \"positive\": 1}\n",
    "    config1._num_labels=2\n",
    "    module2 = BertForSequenceClassification(config1)\n",
    "    module2 = module1.to(model_config.device)\n",
    "    module2.load_state_dict(module1.state_dict())\n",
    "    return module2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be40aab6-e0c5-4bee-891f-a15a26acbb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 9, 13, 14, 15]\n",
      "[0, 4, 9, 10, 12, 14, 15]\n",
      "[0, 4, 9, 13, 14, 15]\n",
      "[0, 4, 9, 10, 12, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "module2 = pppp(module1, ci1, ti1, model_config)\n",
    "module3 = pppp(model, ci1, ti1, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "880a1690-de3b-4617-9b20-0e571472336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(numbers):\n",
    "    # 각 숫자를 2자리 문자열로 변환\n",
    "    print([f\"{num:02}\" for num in numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71744cb9-3929-450d-afcb-9e7a9ac09b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '00', '04', '05', '09', '02', '00', '00', '00', '16', '07', '00', '02', '15', '10', '16']\n",
      "['12', '16', '16', '16', '15', '16', '16', '16', '16', '00', '15', '16', '16', '08', '11', '00']\n",
      "['16', '05', '06', '02', '10', '07', '02', '07', '04', '16', '16', '03', '16', '05', '12', '16']\n",
      "['04', '16', '16', '16', '16', '16', '16', '16', '16', '04', '11', '16', '13', '15', '16', '03']\n"
     ]
    }
   ],
   "source": [
    "pad(ci1.active_node)\n",
    "pad(ci1.dead_node)\n",
    "pad(ti1.active_node)\n",
    "pad(ti1.dead_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efac1a6c-8bf6-4383-bccf-809f2d82ed13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '03', '15', '00', '12', '08', '00', '04', '11', '00']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SDG\n",
    "['16', '06', '00', '00', '00', '00', '00', '01', '00', '16', '11', '00', '00', '00', '00', '08']\n",
    "['00', '03', '11', '16', '16', '15', '16', '07', '15', '00', '01', '16', '16', '15', '16', '00']\n",
    "['15', '00', '00', '00', '00', '00', '00', '01', '00', '15', '03', '00', '00', '00', '00', '11']\n",
    "['00', '09', '11', '14', '11', '13', '12', '10', '11', '00', '02', '12', '05', '12', '10', '00']\n",
    "\n",
    "# IMDb\n",
    "['16', '00']\n",
    "['00', '16']\n",
    "['15', '03']\n",
    "['01', '15']\n",
    "#yahoo\n",
    "['14', '05', '00', '13', '00', '01', '14', '07', '00', '03']\n",
    "['00', '05', '13', '00', '16', '11', '00', '01', '12', '02']\n",
    "['04', '00', '00', '15', '00', '00', '14', '00', '00', '07']\n",
    "['00', '03', '15', '00', '12', '08', '00', '04', '11', '00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c123fa3-5e7a-4c09-8899-5253a986717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 400/400 [01:29<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5684\n",
      "Precision: 0.6835, Recall: 0.8742, F1-Score: 0.6987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86     11184\n",
      "           1       0.37      0.99      0.54      1607\n",
      "\n",
      "    accuracy                           0.79     12791\n",
      "   macro avg       0.68      0.87      0.70     12791\n",
      "weighted avg       0.92      0.79      0.82     12791\n",
      "\n",
      "tensor([[ 0.8224, -0.7373],\n",
      "        [-0.6930, -0.6969],\n",
      "        [ 0.9069,  0.2907],\n",
      "        [ 0.7901,  1.5873],\n",
      "        [-0.3308,  1.3574],\n",
      "        [ 0.8663, -0.2375],\n",
      "        [ 0.0228, -0.1529],\n",
      "        [-0.6217, -0.9786],\n",
      "        [ 0.6345,  0.6874],\n",
      "        [ 1.0046,  1.9743],\n",
      "        [ 0.5596, -0.2493],\n",
      "        [ 0.6060, -0.2655],\n",
      "        [ 0.2072,  1.0275],\n",
      "        [-0.6527, -1.1988],\n",
      "        [-0.5607, -1.1643],\n",
      "        [ 0.2653, -1.1566],\n",
      "        [ 0.5199, -0.8938],\n",
      "        [ 0.7216,  0.9069],\n",
      "        [ 1.0033,  1.9268],\n",
      "        [ 1.0219,  1.3231],\n",
      "        [-0.5373, -1.1344],\n",
      "        [ 0.5647, -0.6701],\n",
      "        [ 0.2969,  0.3264],\n",
      "        [ 0.9493,  0.2100],\n",
      "        [-0.6281, -1.3275],\n",
      "        [-0.5729, -1.1304],\n",
      "        [-0.4216, -0.6303],\n",
      "        [-0.5827, -0.9334],\n",
      "        [-0.2583, -0.9272],\n",
      "        [ 0.8163, -0.1552],\n",
      "        [ 0.7432, -0.3582],\n",
      "        [ 1.0186,  1.9685]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:1')\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|█▉        | 79/400 [00:18<01:13,  4.35it/s]"
     ]
    }
   ],
   "source": [
    "qqqq(module2, conv_collected_input_ids[1], conv_collected_attention_mask[1], conv_collected_labels[1], converted_test_dataloader)\n",
    "qqqq(module3, conv_collected_input_ids[1], conv_collected_attention_mask[1], conv_collected_labels[1], converted_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0ef83-4dba-4488-aa18-00c19b599ce3",
   "metadata": {},
   "source": [
    "imdb-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c5171-1032-4f0e-92a7-b29233e7815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#![image.png](attachment:41cd674b-2d58-4249-87d1-47e1312f4010.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd3a84-d5b9-469e-8803-891e3eff47be",
   "metadata": {},
   "source": [
    "imdb modified channeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beae58-2006-44f6-bd2b-a6e43b183596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#![image.png](attachment:bca24229-36a8-441c-962e-b96a5c25a1fd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631697d-d3bb-4ee6-ae16-a729f2dbe150",
   "metadata": {},
   "source": [
    "imdb not modified channeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e28b2-6b23-4b8f-998e-ea2085709c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#![image.png](attachment:9dfc832b-d226-4115-8fa8-704ba77a8218.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f9321-e309-4434-bc76-7c8408817ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
